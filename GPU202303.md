[Paving the Road to Vulkan on Asahi Linux](https://asahilinux.org/2023/03/road-to-vulkan/)の非公式日本語訳です。

訳注: 本家ブログへのリンクは対応する日本語訳へのリンクに変更
まだ作業中(2023/3/25)

---
# Asahi LinuxでVulkanへの道を拓く

- [前回](https://github.com/asfdrwe/asahi-linux-translations/blob/main/GPU202212.md)

みなさんこんにちは、朝日リナです！✨

ご存知の通り、Asahi Linuxチームの他のメンバーと共に、Apple Siliconプラットフォーム用のオープンソースGPUドライバに取り組んでいます。
それはそれは、ワイルドな道のりでした! 昨年末に何ヶ月もかけてリバースエンジニアリングと開発を行った結果、ドライバの最初のバージョンを
[リリース](https://github.com/asfdrwe/asahi-linux-translations/blob/main/GPU202212.md)しました。しかし、それは始まりに
過ぎませんでした...

今日、Asahi LinuxのGPUドライバの大きなアップデートがリリースされるので、その後の取り組みや、次の展開についてお話したいと思います!

もし今回初めてGPUでの挑戦について読むのであれば、まず[M1 GPU物語](https://github.com/asfdrwe/asahi-linux-translations/blob/main/GPU202211.md)の
記事をチェックした方がいいかもしれませんね。また、Alyssaさんの[ウェブサイト](https://rosenzweig.io/)には、2021年1月までさかのぼる
素晴らしい連載記事がありますので、お見逃しなく! ^^

そして、もしこれが長すぎるなら、Asahi Linuxにとってこれが何を意味するのかを知るために、遠慮なく
[最後までジャンプ](https://github.com/asfdrwe/asahi-linux-translations/blob/main/GPU202303.md#結論)してください!

![Apple M2上で800以上のFPSで動作するXonotic](https://asahilinux.org/img/blog/2023/03/xonotic.png)
Apple M2で800以上のFPSで動作するXonotic

## UAPIって何？
![GPUのレイヤー構造](https://asahilinux.org/img/blog/2023/03/gpulayers.svg)

最近のOSでは、GPUドライバはユーザースペースパートとカーネルパートの2つに分けられています。カーネル部分はGPUリソースの管理とアプリケーション間の
共有方法を担当し、ユーザースペース部分はグラフィックスAPI（OpenGLやVulkanなど）からのコマンドをGPUが実行する必要のあるハードウェアコマンドに
変換することを担当します。

この2つの部分の間には、ユーザースペースAPIまたは『UAPI』と呼ばれるものが存在します。これは、両者の間で通信するためのインターフェースで、
GPUの各クラスに固有のものです! ユーザースペースとカーネルの間の正確な区切りは、各GPUがどのように設計されているかによって異なり、
またGPUの設計によってユーザースペースとカーネルの間で渡されるデータやパラメータが異なるため、新しいGPUドライバーには、それに付随する独自のUAPIが必要となります。

macOSでは、Appleがカーネルドライバとユーザー空間のMetal/GLドライバの両方をコントロールし、新しいmacOSのバージョンの一部として常に同期して更新されるため、
UAPIはいつでも好きなときに変更することができます。ですから、新しいGPUをサポートするために新しい機能が必要になったり、バグや設計上の欠陥を修正したり、
パフォーマンスを向上させるために変更したりしても、問題にはなりません。UAPIを正しく作ることについては、後でいつでも変更できるのであまり心配する必要はないのです。
しかし、Linuxではそう簡単にはいきません...

Linuxカーネルには、超厳密な*ユーザー空間APIの安定性保証*があります。つまり、新しいLinuxカーネルは古いカーネルと同じAPIをサポートしなければならず、
古いアプリやライブラリは新しいカーネルで動作し続けなければなりません。グラフィックスUAPIは非常に複雑で、新しいGPUサポートが任意のドライバに
追加されると頻繁に変更する必要があるため、優れたUAPI設計を行うことが非常に重要になります! 結局のところ、ドライバが上流のLinuxカーネルに
入ってしまえば、古いUAPIとの互換性は絶対に崩せません。もし間違えたら、永遠にそのままでいることになります。このため、UAPIの設計は非常に難しい問題なのです!
Linux DRMサブシステムでは、このような問題を最小限に抑えるために、GPU UAPIに
[特別なルール](https://dri.freedesktop.org/docs/drm/gpu/drm-uapi.html#open-source-userspace-requirements)を設けているほどです...

## UAPIへのささやかな第一歩

ドライバの開発を始めたとき、最初の目標は、GPUとそのファームウェアがどのように動作し、どのようにそれらと対話するのか（図中の『Firmware API』）を
把握することでした。まず、PythonでUSB経由でリモートで動作し、1フレームをレンダリングできるデモを書きました。それから、AlyssaさんのMesaドライバを
GPUに直接接続して、実際のデモやテストアプリを実行できるようにしたいと思うようになりました。Mesaには、Linux DRM UAPIを『偽造』できる
『drm-shim』というテストツールがすでにあったので、Pythonインタプリタを接続するだけでよかったんです！でも、ドライバにはまだ
UAPIがありませんでした...

そこで、[Panfrost](https://docs.mesa3d.org/drivers/panfrost.html)のUAPIをコピー＆ペーストして、少し簡略化し、それを使って実行しました!
drm-shimは本物のLinuxカーネルではないし、Pythonドライバはすべて単一プロセスで動作するデモに過ぎないので、並列処理は不可能でした。
アプリがGPUにコマンドを送信すると、Pythonドライバがすぐにそれを実行し、すべてが完了するまでアプリには戻りません。当時は、USB接続で
すべてを実行するほうがはるかに大きなボトルネックになっていたので、これはまったく問題ではありませんでした!

GPUについていろいろとリバースエンジニアリングしていくうちに、並列処理を適切に行う方法がわかり、GPU上で複数の処理を一度に実行できる
Pythonベースのデモをいくつか作成しました。そんな感じだったので、いざ本物のLinuxドライバをRustで書こうとしたとき、そのための設計に
必要なことはほとんどわかっていたのです。Rustドライバのコアは、複数の処理を同時に実行することに対応しており、実際に12月のリリースでは、
GPUを使用する複数のアプリを同時に実行でき、それらは（原則）互いにブロックすることなく並行してGPUに仕事を送ることが可能です。
でも...すでに 『デモ』UAPIをMesaにつないでいました...当時はそのままにしていたんです!

そのUAPIは何が問題だったのでしょうか？Pythonのデモと同じように、GPUのレンダリングプロセスはすべて同期式でした。アプリがGPUに
ワークを送ると、ファームウェアが実行するためにキューに入れ、その後実行し、すべてが完了してからUAPIコールがアプリに戻るのです。
つまり、1つのアプリの中で、CPUとGPUが並行して何かを処理することはできないんです! それだけでなく、CPUとGPUの間を行き来するための
レイテンシーが発生するため、さらにパフォーマンスが低下してしまいます...

![レンダリング処理の流れ](https://asahilinux.org/img/blog/2023/03/demo-sync.svg)

ありがたいことに、GPUもCPUもとても速いので、こんなひどい設計でも、60FPSで使えるデスクトップを提供できるほど、物事は速く動きました。🚀

しかし、これでは明らかにダメで、上流に行こうとするととんでもないデザインになってしまうので、何か良い方法を考えなければなりませんでした。

## GPUの同期

並列処理を始めると、すべての同期をどのようにとるかという問題にぶつかります。つまり、CPUがGPUにワークを依頼した後、その結果を利用する前に、
GPUが終了するのを待たなければならないことがあります。それだけでなく、GPUに送られた異なるビットの作業は、頻繁に相互依存しています!
これらの依存関係はアプリをまたいで広がることもあります。ゲームでは複雑な方法で互いに依存し合う複数のレンダーパスをキューに入れ、
最終的なシーンをWaylandコンポジターに渡す必要がありますが、このコンポジターはシーンのレンダリングが終わって初めてコンポジットを
開始することができます。さらに、Waylandコンポジッターは、新しいフレームを表示するために、ディスプレイコントローラ上でページフリップを
キューに入れなければなりませんが、これはフレームのレンダリングが終わってからしかできません!

![依存関係](https://asahilinux.org/img/blog/2023/03/dependencies.svg)

これらのことは、すべてが正しく動作するためには正しい順序で起こる必要があり、UAPIはそのためのメカニズムを提供する必要があります。
グラフィックスAPIが長年にわたって変化するにつれて、この方法が変化してきました。従来、UAPIはOpenGLの『暗黙の同期(implicit sync)』モデルに
基づいていました...

## 暗黙の同期(implicit sync)

暗黙の同期モデルは、同期がテクスチャやフレームバッファのようなバッファーと結びついているという考えに基づいています。作業がGPUに送られると、
カーネルドライバはどのバッファから読み出し、どのバッファに書き込むかを追跡します。もし、以前に提出されたGPUワークによって書き込まれた
（または書き込まれる予定の）バッファから読み書きしている場合、ドライバはそれらのジョブが完了するまで実行を開始しないようにします。
内部的には、各バッファに1つ以上の*DMA fence*を持たせ、読み込む者と書き込み者を追跡し、読み込む者が前の書き込み者をブロック
できるようにすることで機能します。

これは動きます! アプリ開発者は、同期についてあまり気にする必要がありません。テクスチャにレンダリングして、それを後で使用するだけです。
ドライバは、依存関係を追跡することによって、すべてが順次実行されているように見せます。これはアプリ間でも機能しますし、GPUと
ディスプレイコントローラの間でも機能します。

残念ながら、このモデルはあまり効率的ではありません。つまり、カーネルは、すべてのレンダリングジョブが使用する可能性のあるGPUバッファを
すべて追跡する必要があるのです! 例えば、あるゲームが100枚のテクスチャを使用するとします。つまり、シーンをレンダリングするたびに、
カーネルは誰もそのテクスチャに書き込んでいないことを確認し、読み込み中であることをマークしなければならないのです。しかし、
なぜ誰も書き込まないのでしょうか？結局のところ、ほとんどのテクスチャは一度メモリに読み込まれたら、二度と触ることはありません。
しかし、カーネルはそのことを知りません...

このモデルは、今日、すべてのLinuxメインラインGPUドライバで対応しています! （amdgpuのように）いくつかのドライバは明示的な同期
(explicit sync)に対応するようになりましたが、それらはまだ覆いの下で完全な暗黙の同期に対応しています。UAPI の安定性ルールを
覚えていますか...？

## 明示的な同期(explicit Sync)

その後、Vulkanが登場し、もっと良い方法があると伝えてきました。Vulkanではバッファの暗黙の同期がありません。その代わりに、アプリ開発者は、
GPUに送るもの間の依存関係を手動で追跡する責任があり、Vulkanは、システムに必要なものを伝えるためのいくつかのツールを提供しています。
バリア(barrier)やイベント(event)、フェンス(fence)、タイムラインセマフォ(timeline semaphore)です。

Vulkanはかなり複雑なので詳細は省きますが...基本的には、これらのツールによって、アプリはいつ何を待つ必要があるのかを細かく制御することに
なります。暗黙のバッファ同期がなくなるのは素晴らしいことです!カーネルドライバは、もはや何十、何百ものバッファを追跡する必要はなく、
アプリが要求する非常に特殊な同期要件だけを追跡します。

(ちなみに、Metalはなぜか明示的な同期と暗黙の同期の両方に対応していますが、話がそれます...)

覆いの下でLinuxは、同期オブジェクト（sync object)と呼ばれる標準的なメカニズムを使って明示的な同期を実装しています。各同期オブジェクトは
基本的に完了のためのコンテナであり、実際にはDMA fenceです。非同期プログラミングのフレームワークを使ったことがある人なら、おそらく*プロミス(promise)*
という言葉を聞いたことがあると思います。DMA fenceは、基本的にGPU版の*プロミス*なのです! 同期オブジェクトは[もともとOpenGLの概念](https://www.khronos.org/opengl/wiki/Sync_Object)ですが、Vulkanのより複雑な要件に対応するため、その後、適応・拡張されました。

明示的な同期の世界では、アプリがカーネルにGPUワークを送るとき、*入力*同期オブジェクトのリストと*出力*同期オブジェクトのリストを渡します。
カーネルドライバはすべての入力同期オブジェクトをチェックし、そのfenceを GPUワークの依存関係として登録します。次に、ワーク用の新しい
（保留中の）完了フェンスを作成し、それを出力同期オブジェクトに挿入します（同期オブジェクトはfenceの*コンテナ*であるため、置き換える
ことができることを覚えておいてください）。そして、ドライバはワークを実行キューに入れ、すぐにユーザースペースに戻ります。そして、
バックグラウンドでは、すべての依存関係のフェンスがシグナルされたときにのみ、ワークの実行が許可され、ワークが終わると、自身の完了
fenceをシグナルします。ふぅーっ! 素晴らしく、クリーンで、モダンなカーネルの同期用 UAPI です!

ただし、問題があります...

## ウィンドウシステムに関する問題

1つのアプリの中では、Vulkanが同期の面倒をみてくれます。しかし、ゲームがWaylandコンポジターにフレームを送信するときのように、
アプリ間で同期するのはどうでしょうか？これには同期オブジェクトが使えますが...Linuxの同期オブジェクトが発明された時点で、Waylandは
10年近くも前のものです!

もちろん、デスクトップLinuxの既存の*ウィンドウシステム統合*規格はすべて暗黙の同期を前提としています。明示的な同期を追加することも
できますが、それは後方互換性を壊すことになります...

既存のLinuxドライバがやっていることは、両方に対応することです。カーネルドライバに、読み書きするバッファのリストを渡し、ドライバが
他のプロセスと共有されていないと知っているテクスチャなどを除外することができます。そして、カーネルは暗黙のうちにこれらのバッファと同期し、
明示的に同期オブジェクトと同期するのです。これはうまくいくのですが、やはりドライバが複雑になりますね...

必要なのは、ドライバごとに車輪を再発明することなく、暗黙の同期と明示的な同期の世界を橋渡しする方法なのです。ありがたいことに、Linux DRM
サブシステムの開発者たちは、この問題を解決するために懸命に働いており、つい数ヶ月前にようやく解決しました!

## 両方の世界の架け橋

暗黙の同期はバッファに付けられたDMA fenceを使い、明示的な同期は同期オブジェクトの中のDMA fenceを使うことで動作すると言ったのを覚えていますか？

昨年のAsahi ドライバのリリースの数ヶ月前、2022年10月にLinux 6.0がリリースされました。DMA fenceをDMA-BUFにインポートするAPIと、DMA
fenceをDMA-BUFからエクスポートするAPIの2つの新しい汎用DRM APIがリリースされました。

既存の汎用同期オブジェクトAPIと合わせて、このギャップを完全に解消することができます! ユーザースペースアプリは、DMA-BUF（他のプロセスと
共有するバッファ）からfenceを取り出し、それをGPUジョブが待機するための同期オブジェクトに変え、そのジョブの出力同期オブジェクトを取り出し、
他のプロセスと共有できる別のDMA-BUFにそのfenceを挿入できるようになりました。

もっと詳しく知りたいなら、Faith Ekstrandさんがこれを扱った
[素晴らしい記事](https://www.collabora.com/news-and-blog/blog/2022/06/09/bridging-the-synchronization-gap-on-linux/)を書いています。Faithさんは素晴らしいメンターでもあり、Faithさんの助けなしには、このUAPI設計のすべてを理解することはできなかったでしょう。

素晴らしいです!これで問題はすべて解決です! でも、『悪魔は細部に宿る』という言葉があるように...

## OpenGLがお呼びです...

明示的な同期は素晴らしいですが、Vulkanドライバはまだなく、OpenGLドライバがあります。どうすればうまくいくのでしょうか?

OpenGLは、暗黙の同期モデルに非常によく基づいています。なので、OpenGLドライバを明示的同期UAPIで動作させるためには、ドライバが両方の世界の
橋渡しをする必要があります。もちろん、バッファごとにfenceをインポート/エクスポートすることに戻ることもできますが、そうすると、そもそも
カーネルで暗黙の同期を行うよりもさらに遅くなります...

(作業中2023/3/25)

バッファの同期問題を無視しても、暗黙の同期の世界では、カーネルはGPUが必要とするすべてのバッファを追跡しています。しかし、明示的な同期の世界では、それは起こりません。このことは、アプリがテクスチャを使用してレンダリングした後、テクスチャを解放して破棄することができることを意味します。Vulkanではアプリのバグになりますが、OpenGLではうまくいくはずです...

Mesaの明示的同期は、主にVulkanドライバに使われてきましたが、純粋な明示的同期Linux GPUドライバはまだメインラインには存在しないので、Mesaにはこれを行うOpenGL（Gallium）ドライバは存在しません! そのため、参照するコードがなく、自分自身でこの機能を実現する方法を考えなければなりませんでした^^;;。

そこで私は、Alyssaと私が取り組んでいたMesaドライバで明示的同期を動作させる方法を探すことにしました。ありがたいことに、それほど大きなリファクタリングは必要ないことが判明しました。

タイルベースのモバイルGPUで優れたパフォーマンスを発揮するためには、OpenGLをハードウェアに直接マッピングするだけではダメなんです。タイルベースのGPUでは、物事はすぐにフレームバッファに直接レンダリングされるわけではありません。その代わりに、まずジオメトリの全シーンが収集され、バーテックスシェーダを経て、画面位置に基づいてタイルに分割され、最後に超高速タイルメモリでタイルごとにレンダリングされてからフレームバッファに書き出されます。レンダリングを多くの小さなパスに分割すると、フレームバッファを毎回ロードして保存することになり、これらのGPUでは非常に遅くなります。しかし、OpenGLでは、アプリケーションは好きなだけフレームバッファを切り替えることができ、多くのアプリケーションやゲームでは常にこの操作が行われています。

そこでアリッサは、Panfrostドライバ用にバッチ追跡システムを開発しました（Freedreno用のRob Clarkのオリジナル実装が元になっています）。このアイデアは、仕事をすぐにGPUに送るのではなく、バッチに集めるというものです。アプリが別のフレームバッファに切り替わったら、そのバッチはそのままにして、新しいバッチを作る。アプリが元のフレームバッファに戻ったら、またバッチを切り替えて、元のバッチに仕事を追加し続けます。そして、実際にレンダリングが必要になったら、完全なバッチをハードウェアに提出します。

もちろん、ここで問題があります...アプリが以前にレンダリングしたフレームバッファから読もうとした場合はどうでしょうか？バッチ追跡システムは、各バッファのリーダとライタを追跡し、その出力が現在のバッチに必要なときにいつでもGPUにバッチをフラッシュします。

...ちょっと待てよ、これって暗黙の了解みたいな感じじゃないのか？

ドライバには、私が必要とするコアな部分がすべて備わっていることがわかったのです。バッチトラッキングは、以下のことが可能です。

- 同時に独立した複数のGPU作業のビットを追跡することができます。
- 読み書きされたバッファに基づいて、それらの依存関係を追跡する。
- バッチがGPUに投入されるまで、必要なバッファを維持する。

バッチ追跡システムを拡張して、未提出のGPU作業だけを追跡するのではなく、カーネルに提出されたがまだ完了していない作業も追跡するようにすればいいのです。そうすれば、既存のリーダ/ライタの機械を使って、どのバッファが読み書きされたかを把握することができます。バッチは1つのキューでGPUに送信され、順番に実行されるので、各バッチの前にGPUバリアを完全に追加する限り、バッチ間の同期を心配する必要はほとんどありません。

今回のコミットは中規模になりましたが、それほど扱いにくい[もの](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21620/diffs?commit_id=04387269dd3f054e2d1c9d99dc5650085dd417e9)ではありませんでした。変更のほとんどはバッチ追跡のコードで、アクティブではなくサブミットされたバッチのアイデアを扱うために既存のコードを拡張しただけでした。そして、既存のLinux syncオブジェクトAPIを使って、バッチが実際に完了したタイミングを把握し、最後にバッチをクリーンアップするだけです。これで、明示的な同期がうまくいきました。

まあ...そんな感じです。サーフェスレス（オフスクリーン）のレンダーテストではうまくいきましたが、他のアプリと共有するバッファの暗黙の同期をどう扱うかという厄介な問題が残っていました...。

## 暗黙のシンクロの数々の鋭利な刃物...。

実は、私が参照できるドライバが1つあるんです。まだマージされていませんが、Intelの新しい[Xeカーネルドライバ](https://lore.kernel.org/dri-devel/20221222222127.34560-1-matthew.brost@intel.com/)も真新しい純粋な明示的同期ドライバで、[Mesa側](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/20418)ではMesaの既存のIntel Irisドライバにそのサポートを追加しています。実際、AsahiドライバのUAPIは、（Faithの提案で）Xeのものに大きくインスパイアされているんだ！」。

これら2つのGPUの動作方法とドライバの設計は、ドライバ内で明示的な同期で内部バッチ追跡を動作させる方法の例としてXe/Irisを使うには違いすぎますが、少なくとも共有バッファを使った暗黙の同期をどう扱うかを見てみることはできます。このアイデアは非常に単純であることがわかりました。

- GPUに作業を送信する前に、使用されているすべてのバッファを調べて共有バッファを見つけ、そのDMAフェンスを取得して入力同期オブジェクトとしてセットアップします。
- 作業終了後、出力同期オブジェクトを取り出し、そのフェンスを取り出して、再びすべての共有バッファに設置します。

これで完成です。暗黙の同期ウィンドウシステム統合のサポートです!

そして、WebGLのテストでFirefoxがクラッシュするようになりました...。

## シュレーディンガーのバッファシェアリング

新しいUAPI設計の一部として、ドライバはバッファが共有される可能性があるときにカーネルに伝えることになっています。カーネルは、アプリが割り当てたすべてのバッファについて知る必要があり、メモリ管理のコーナーケース（私たちのドライバではまだ実装されていませんが、今後実装される予定です）のために、GPUで何かをするときにそれらをロックする必要があります。そのため、i915のような既存のドライバでは、GPUの作業が送信されると、たとえそれらがすべてGPUによって使用されていなくても、カーネルが何千ものバッファをロックすることになります。バッファを非共有とマークすると、カーネルはそのバッファを他の非共有バッファとグループ化して、同じロックを共有するのです。つまり、プロセス間でバッファを共有することは決してできず、カーネルがこれを防いでくれるのです。MesaのGalliumドライバ層には、バッファが共有される可能性があるかどうかのフラグがあり、作成時に渡されるので、簡単ですよね？

ただし、これがOpenGLで合法であることを除きます。

1. `glTexStorage2D(...)` (テクスチャの作成、ストレージの確保、データのアップロード)
2. `eglCreateImageKHR(...)` （テクスチャをEGL画像にする）
3. `eglExportDMABUFImageMESA(...)` (エクスポートする)

OpenGLドライバには、作成時にテクスチャを共有することを知る方法がありません。共有されていないように見えて、いきなり共有されてしまうのです。おっとっと！」。

これは、明示的な同期とは関係ない[別の理由](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/13154)で、Mesaに存在する問題であることが判明しました。そこで、バッファを再割り当てして共有可能にコピーする[コードをそこに追加](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21620/diffs?commit_id=c41f10eb9ebf82f9d37f83ec0a182215600327cd)しました。これは最速の解決策ではないし、将来的に変更するかもしれませんが、今のところうまくいっています。

すべて完了しましたね？

```
21:05 <alyssa> lina: 最新のブランチでは supertuxkart にマゼンタの長方形が残っています。
21:20 <jannau> 2つの起動のうちの1つでまだ起動中ですか？ プラズマ/ウェイランド下のストリームでは問題ありませんでした。
21:21 <alyssa> yes
21:22 <alyssa> in sway if it matters.
21:22 <alyssa> nautilusでも時々見かけました。
21:23 <alyssa> そうですね、gnomeでは再現できません。
21:23 <alyssa> しかし、スウェーで簡単に再現できる。
21:23 <alyssa> だから......もっとWSIのジャンクを
21:23 <alyssa> ASAHI_MESA_DEBUG=syncで解消されますね。
21:24 <alyssa> それで...揺れで再現されるだけのWSI同期問題
21:24 <alyssa> そしてsupertuxkartは最も簡単に再現できる。
03:20 <lina> alyssa: 起動時のみ、揺れ時のみ？うーん、このままではリリースをブロックしてはいけないもののように思えてきました^^;。
03:20 <lina> ASAHI_MESA_DEBUG=syncで治るのはstkだけなのか、sway全部なのか？
03:26 <alyssa> lina: stkだけsyncでswayはsyncにしない設定で十分です。
03:27 <alyssa> しかし、壊れているのはsupertuxkartだけでなく、すべてです。
03:27 <alyssa> そう、これはリグレッションであり、絶対にリリースをブロックするものです。
```

## シュレーディンガーのバッファ共有、その2...

長くなりましたが、アプリでもできることが判明しました。

1. フレームバッファ（共有可能）を作成するが、まだ共有しない。
2. バッファにレンダリングする。
3. それを共有する。

レンダリングコマンドを送信すると、まだ共有されていないように見えるので、ドライバは暗黙の同期ダンスをしない...そして、アプリがそれを共有するとき、それは遅すぎるし、それは正しいフェンスがそれに添付されていない。そして、アプリが共有したときにはもう遅く、適切なフェンスもついていません。反対側にいる人はバッファを使おうとし、レンダリングが完了するまで待ちません。おっとっと！」。

そこで、提出されたけれども完成していないすべてのバッチの同期オブジェクトIDを記録しておき、書き込まれたすべてのバッファにそれを付加する仕組みを追加する必要がありました。そうすれば、バッチが完了したとわかる前にバッファが共有された場合、過去にさかのぼってフェンスを取り付けることができます。

面白いことに、Xeのマージリクエストに取り組んでいるIntelの人たちにこの話を持ちかけたところ、彼らはこの話を聞いたことがなかったんです。彼らのドライバにも同じバグがありそうです...Swayでテストを始めた方がいいかもしれませんね^^; 。

もう終わったの？まだつぶすべきバグがあるんだけどね...カーネルについてはまだ話してないんだ

## 明示的な同期とRustの出会い

以前のバージョンのAsahi DRMカーネルドライバは、非常にシンプルなUAPIを持っていたため、カーネルの他の部分とどのように相互作用するかについて、かなり素っ気ないものでした。私は、これらのDRM APIのためのRust抽象化機能を追加するだけでよかった。

- `drv`と`device`、DRMドライバとデバイス処理の中核をなすものです。
- `file`、DRMドライバの中核であり、デバイスを扱うdrvとdevice。DRMドライバがユーザ空間とやりとりする
- `gem`、ユニファイドメモリを搭載したGPUのメモリを管理するためのものです。
- `mm`、 汎用的なメモリ範囲確保ツールで、私のドライバではいくつかのことに使用しています。
- `ioctl`、 UAPI用のDRM ioctl番号を計算するためのラッパーです。

適切な明示的同期サポートを追加するために、私は多くの新しい抽象化を追加する必要がありました。

- `dma_fence`、 コアとなるLinuxのDMAフェンス機構です。
- `syncobj`、DRMの同期オブジェクトAPIです。
- `sched`、実際にGPU作業をキューに入れ、スケジューリングするDRMコンポーネントです。
- `xarray`、 基本的に int → void * のマッピングであるカーネルの汎用データ構造で、VM やキューのようなユーザー空間の UAPI オブジェクトを固有の ID で追跡するために使用しています。

DRMの抽象化をすべて[送信](https://lore.kernel.org/asahi/687b54e7-b9a6-f37b-e5e6-8972e3670cc1@asahilina.net/T/#t)して初期レビューを受け、できるだけ早くアップストリームに上げられるようにし、その後、ドライバ自体をアップストリームに上げることにしました

この作業の一環として、DRMスケジューラコンポーネントのメモリ安全性バグを2つ発見しました。これはAlyssaや他の開発者がカーネルで失敗する原因となっていたもので、Rustドライバの作業は、この共有コードを使用する他のカーネルドライバにも利益をもたらします。一方、Rustコードのバグが原因でカーネルが停止したという報告はまだ全くありません～✨。

## さらなる進化を遂げた!

明示的な同期がこのリリースの最大の変更点ですが、それ以外にもいろいろあります。UAPIを最終バージョンにできるだけ近づけたいので、さらに多くのものを追加することに取り組んでいます。

- 複数のGPU VM（仮想メモリアドレス空間）と、Xe UAPIモデルに基づくGEMオブジェクトバインディングを追加し、将来のVulkan要件をサポートします。
- カーネルドライバがGPUジョブの実行結果をMesaに送り返すための結果バッファです。これには統計やタイミングのようなものだけでなく、コマンドが成功したかどうかや詳細な障害情報も含まれるので、Mesaで冗長な障害デコードを正しく実行できます
- コンピュートシェーダーを実行するための、コンピュートジョブのサポート。まだMesa側で作業中ですが、ほとんどのテストに合格し、最終的には[Rusticl](https://www.phoronix.com/news/Rusticl-OpenCL-3.0-Conformance)でOpenCLサポートを追加するのに十分なはずです。
- 複数のGPUジョブを一度に投入し、同期オブジェクトを使用せずに、それらの依存関係を直接指定することができます。これにより、GPUファームウェアが自律的にすべてを実行することができ、DRMスケジューラーを毎回経由するよりもずっと効率的です。Galliumドライバはまだこれを使用していませんが、おそらく将来的に使用することになるでしょうし、私たちの次期Vulkanドライバは間違いなく使用することになるでしょう。すべてのキューイングがどのように機能するかについては、[多くの微妙な点](https://github.com/AsahiLinux/docs/wiki/SW:AGX-driver-notes#queues)があります。
- blitコマンドのスタブサポート。これらがどのように機能するかはまだ分かりませんが、少なくともUAPIでいくつかのスケルトン・サポートがあります。

結局、[workqueue](https://github.com/AsahiLinux/linux/blob/gpu/rust-wip/drivers/gpu/drm/asahi/workqueue.rs)のコードをリファクタリングして、全く新しい[queue](https://github.com/AsahiLinux/linux/tree/gpu/rust-wip/drivers/gpu/drm/asahi/queue)モジュールを追加しました。これは、同期オブジェクトを使用してコマンドの依存関係と完了を追跡し、DRMスケジューラで作業を管理するためのすべてのインフラストラクチャを追加するものです。ふぅ〜。

## 結論

では、今日のAsahi Linuxリファレンス・ディストロのユーザーにとって、このことは何を意味するのでしょうか？それは...物事がより速くなったということです!

MesaドライバがGPUとCPUの作業をシリアライズしなくなったので、パフォーマンスが大幅に改善されました。同じハードウェア（M2 MacBook Air）のmacOSの約600*よりも速いのです！今、私たちはXonoticを800 FPS以上で動かすことができます。これは、オープンソースのリバースエンジニアリングGPUドライバが、実世界のシナリオでAppleのドライバを打ち負かす力を本当に持っていることを証明しています。

それだけでなく、私たちのドライバはdEQP-GLES2およびdEQP-EGL適合性テストに100%合格しており、これはそのバージョンのmacOSよりも優れたOpenGL適合性です。もちろん、それだけにとどまらず、Alyssaのたゆまぬ努力により、SLES 3.0と3.1のフルサポートが進行中です。ドライバの機能サポートの進捗は、[Mesa Matrix](https://mesamatrix.net/)で確認できます。この数ヶ月の間に、他にも多くの改良がなされましたが、全体としてより良く、よりスムーズに動作していることを実感していただけると思います

もちろん、明示的同期ドライバで暗黙的同期をサポートするようになったことで、新たに発生するコーナーケースもたくさんあります。少なくとも1つのマイナーなリグレッション（KDE起動時に数フレームにわたって短いマゼンタ色の四角が表示される）をすでに知っていますし、おそらく他にもあると思いますので、問題があれば[GitHubのトラッカー](https://github.com/AsahiLinux/linux/issues/72)でバグを報告してください! 問題報告が多ければ多いほど、特に問題を再現する簡単な方法があればあるほど、私たちはこれらの問題をデバッグして修正するのが容易になります^^。

* 他の違いもあるので、正確な数字をあまり深刻に考えないでください（XonoticはmacOSのRosettaで動作していますが、Retina以外のアプリであるため、そこでも低い解像度でレンダリングされていました）。要は、結果は同じレベルであり、私たちは今後もドライバーの改良を続けていくだけです! *

## 手に入れよう!

すでにGPUドライバを使用している場合は、システムをアップデートして再起動するだけで、新しいバージョンを入手できます。UAPIが（かなり）変わったので、再起動するまではアプリが起動しなくなったり、ソフトウェアレンダリングで起動したりすることに留意してください。

新しいドライバをまだ試していない場合は、パッケージをインストールしてください。

```
$ sudo pacman -Syu
$ sudo pacman -S linux-asahi-edge mesa-asahi-edge
$ sudo update-grub
```

次に、KDEを使用している場合は、Waylandセッションもインストールされていることを確認します。

```
$ sudo pacman -S plasma-wayland-session
```

その後、再起動し、ログインウィンドウでWaylandセッションを選択することを確認してください。Xorgから切り替えた場合、KDEがモニタを切り替えたと勘違いするので、KDEの設定でディスプレイスケールを再設定する必要があることを忘れないでください。ラップトップでは通常150%が良い選択です。変更を完全に反映させるために、ログアウトして再ログインすることを忘れないでください

## 次は何でしょう？

UAPIが整い、多くのネイティブARM64 Linuxゲームが正常に動作するようになったので...ドライバで何が実行できるかを確認する時です! OpenGL 3.xのサポートは、完全ではないものの、多くのゲーム（DarwiniaやSuperTuxKartの高度なレンダラーなど）を実行するには十分すぎるほどです。しかし、ほとんどのゲームはARM64 Linuxでは利用できないので...[FEX](https://github.com/FEX-Emu/FEX)の出番です!

FEXは16Kページを使っているので、標準的なAsahi Linuxカーネルビルドでは動作しませんが、4Kページのサポートは実はそれほど難しいものではありません...そこで今週から、Asahi GPUドライバーに4Kサポートを追加し、途中で発生した問題を修正するつもりです！そして、この上でSteamとProtonを使ってみるつもりです。Steamのゲームライブラリのうち、どれだけのものが現状のドライバで実行できるのか、見てみましょう。きっと驚くと思いますよ...（Portal 2を覚えていますか？OpenGL 2.1しか必要ないんですよ。ドライバの3.xサポートは今日までなので、きっと楽しいことがたくさんあるはずです～✨)

私の仕事に興味がある方は、[@lina@vt.social](https://vt.social/@lina) で私をフォローするか、私の [YouTube チャンネル](https://youtube.com/AsahiLina)を購読してください! 水曜日と金曜日にAsahi GPUドライバに関する私の作業を配信しているので、興味があれば気軽に私の配信に立ち寄ってみてください

もし私の仕事をサポートしたいのであれば、[GitHub Sponsors](http://github.com/sponsors/marcan)のmarcanのAsahi Linuxサポートファンドに寄付するか、[Patreon](https://patreon.com/marcan)に寄付すると、私も助かりますよ。そして、Vulkanドライバを楽しみにしている人は、Ellaの[GitHub Sponsors](https://github.com/sponsors/Ella-0)のページをチェックしてみてください アリッサは自分では寄付を受け付けていませんが、代わりに[Software Freedom Conservancy](https://sfconservancy.org/)のような慈善団体に寄付してくれるとうれしいです。(いつか彼女を説得してM2を買ってもらうかもしれませんが...^^;;)

#### 朝日リナ - 2023-03-20


