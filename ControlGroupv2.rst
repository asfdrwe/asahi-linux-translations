`Control Group v2 <https://docs.kernel.org/admin-guide/cgroup-v2.html>`_  の非公式日本語訳です。
ライセンスは原文のライセンス(GPL-2.0のはず)に従います。

訳注: 

* まだDeepLの結果をはる途中(2024/3/8)

.. _cgroup-v2:

================
Control Group v2
================

:日付: October, 2015
:著者: Tejun Heo <tj@kernel.org>

本書は、cgroup v2 のデザイン、インターフェイス、および規約に関する権威ある文書です。
cgroup v2 の設計、インターフェイス、規約に関する権威ある文書です。
コアおよび特定のコントローラ動作など、cgroup のユーザーランドから見えるすべての側面について説明します。 将来の変更はすべて
今後の変更はすべてこのドキュメントに反映する必要があります。 v1 のドキュメントは
v1 のドキュメントは https://docs.kernel.org/admin-guide/cgroup-v1/index.html#cgroup-v1 にあります。

.. content

   1. はじめに
     1-1. 用語解説
     1-2. cgroupとは？
   2. 基本操作
     2-1. マウント
     2-2. 工程とネジの整理
       2-2-1. プロセス
       2-2-2. スレッド
     2-3. [未登録の通知
     2-4. コントローラーの制御
       2-4-1. 有効化と無効化
       2-4-2. トップダウンの制約
       2-4-3. 内部プロセス制約なし
     2-5. 権限委譲
       2-5-1. 委任のモデル
       2-5-2. 委任の封じ込め
     2-6. ガイドライン
       2-6-1. 一度整理してコントロールする
       2-6-2. 名前の衝突を避ける
   3. リソース分配モデル
     3-1. 重み
     3-2. 限界
     3-3. プロテクション
     3-4. 配分
   4. インターフェースファイル
     4-1. フォーマット
     4-2. 規約
     4-3. コアインターフェースファイル
   5. コントローラ
     5-1. CPU
       5-1-1. CPUインターフェースファイル
     5-2. メモリー
       5-2-1. メモリーインターフェースファイル
       5-2-2. 使用ガイドライン
       5-2-3. メモリの所有権
     5-3. IO
       5-3-1. IOインターフェースファイル
       5-3-2. ライトバック
       5-3-3. IOレイテンシ
         5-3-3-1. IOレイテンシ・スロットリングの仕組み
         5-3-3-2. IOレイテンシのインターフェースファイル
       5-3-4. IO優先度
     5-4. PID
       5-4-1. PIDインターフェースファイル
     5-5. Cpuset
       Cpusetインターフェースファイル
     5-6. デバイス
     5-7. RDMA
       5-7-1. RDMA インターフェースファイル
     5-8. HugeTLB
       HugeTLBインターフェースファイル
     5-9. その他
       5.9-1 その他のcgroupインターフェースファイル
       5.9-2 マイグレーションとオーナーシップ
     5-10. その他
       perf_event
     5-N. 非規範情報
       5-N-1. CPUコントローラルートcgroupプロセスの動作
       5-N-2. IO コントローラルート cgroup プロセスの動作
   6. 名前空間
     6-1. 基本
     6-2. ルートとビュー
     6-3. マイグレーションと setns(2)
     6-4. 他の名前空間との相互作用
   P. カーネルプログラミングに関する情報
     P-1. ファイルシステムによるライトバックのサポート
   D. 非推奨のv1コア機能
   R. v1の問題点とv2の根拠
     R-1. 複数の階層
     R-2. スレッドの粒度
     R-3. 内部ノードとスレッド間の競争
     R-4. その他のインターフェイスの問題
     R-5. コントローラーの問題と対策
       R-5-1. メモリー

はじめに
============

用語解説
-----------

"cgroup "は "control group "の略で、決して大文字にしない。 単数形は
単数形は機能全体を指定するために使用されます。
cgroup controllers "のように修飾語としても使われます。 明示的に複数の
複数のコントロールグループを明示的に指す場合は、複数形の "cgroups "を使用します。


cgroupとは？
---------------

cgroup はプロセスを階層的に整理し、階層に沿ってシステムリソースを
制御および設定可能な方法で、階層に沿ってシステムリソースを分配する仕組みです。
設定可能な方法です。

cgroup は大きく分けてコアとコントローラの2つの部分で構成されます。
cgroup コアは主にプロセスを階層的に整理する役割を担います。
プロセスを階層的に編成します。 cgroup コントローラは通常、次の役割を担います。
階層に沿って特定のタイプのシステムリソースを配布する。
リソース配布以外の目的を果たすユーティリティコントローラもあります。
ユーティリティコントローラもあります。

cgroup はツリー構造を形成し、システム内のすべてのプロセスは1つの
に属します。 プロセスのすべてのスレッドは
同じcgroupに属する。 プロセスのすべてのスレッドは同じcgroupに属します。
に配置される。 プロセスは
することができます。 プロセスの移行は、すでに存在する子孫プロセスには影響しません。
プロセスの移行は、すでに存在する子孫プロセスには影響しません。

特定の構造的制約に従って、コントローラはcgroup上で選択的に有効または無効にすることができる。
を選択的に無効にすることができる。 コントローラの動作はすべて
コントローラがcgroupで有効になると、すべてのプロセスに影響する。
に属するすべてのプロセスに影響します。
に属するすべてのプロセスに影響します。 コントローラがネストした
コントローラがネストされた cgroup で有効になると、常にリソース配分がさらに制限されます。 そのため
階層内のルートに近いところで設定された制限は、遠いところから上書きすることはできません。
を上書きすることはできません。


基本操作
================

マウント
--------

v1 と異なり、cgroup v2 には階層が 1 つしかありません。 cgroup v2
階層は次のマウントコマンドでマウントできます::

  # mount -t cgroup2 none $MOUNT_POINT

cgroup2 ファイルシステムのマジックナンバーは 0x63677270 ("cgrp") です。 全ての
v2をサポートし、v1階層にバインドされていないすべてのコントローラは、自動的にv2階層にバインドされます。
自動的にv2階層にバインドされ、ルートに表示されます。
v2階層でアクティブに使用されていないコントローラは、他の階層にバインドすることができます。
他の階層にバインドすることができます。 これにより、v2階層とレガシーv1階層を混在させることができます。
v2階層とレガシーv1複数階層を完全に下位互換性のある方法で混在させることができます。

コントローラを階層間で移動できるのは、そのコントローラが現在の階層で参照されなくなってからです。
が現在の階層で参照されなくなった後にのみ、階層を越えて移動できます。 グループ単位の
コントローラステートは非同期に破棄され、コントローラは
コントローラの参照が残っている可能性があるため、コントローラは
にすぐに表示されないことがあります。
同様に、コントローラは、完全に無効になっている必要があります。
コントローラが他の階層で使用できるようになるには、時間がかかります。
コントローラが他の階層で使用できるようになるまで、時間がかかる場合があります。
さらに、コントローラ間の依存関係により、他のコントローラも無効にする必要があります。
さらに、コントローラ間の依存関係により、他のコントローラも無効にする必要があります。

さらに、コントローラ間の依存関係により、他のコントローラも無効にする必要があります。
v2と他の階層間でコントローラを動的に移動することは、開発時や手動設定時には便利ですが、本番環境での使用は強く推奨されません。
本番環境での使用は強く推奨されません。 以下のように決定することを推奨します。
を使用する前に、階層とコントローラの関連付けを決定することを推奨します。
を決定することを推奨します。

v2への移行中に、システム管理ソフトウェアがv1のcgroupファイルを自動マウントする可能性があります。
システム管理ソフトウェアがv1 cgroupファイルシステムを自動マウントする可能性があります。
を乗っ取る可能性があります。テストと実験を容易にするために
カーネルパラメータ cgroup_no_v1= により、v1 のコントローラを無効にし、v2 への移行を容易にします。
v1 でコントローラを無効にし、v2 で常に使用できるようにします。

cgroup v2 は現在、以下のマウントオプションをサポートしています。

nsdelegate
	cgroup 名前空間をデリゲーションの境界とみなす。 この
	オプションはシステム全体に適用され、マウント時に設定するか、initネームスペースから
	initネームスペースからのリマウントによってのみ設定できます。 マウントオプションは
	オプションはinitネームスペース以外のマウントでは無視されます。 詳細は
	権限委譲セクションを参照してください。

  favordynmods
        タスクの移行やコントローラのオン/オフなどの動的な cgroup 変更の待ち時間を短縮します。
        タスクマイグレーションやコントローラーのオン/オフなどの動的な
        フォークや終了などのホットパス操作をより高価にします。
        cgroupを作成し、コントローラを有効にし
        コントローラを有効にし、CLONE_INTO_CGROUP でシードするという静的な使用パターンは、このオプションの影響を受けません。
        このオプションの影響を受けません。

  memory_localevents
        memory.events に現在の cgroup のデータのみを入力します、
        サブツリーではありません。これはレガシーな動作です。
        サブツリーのカウントを含む。
        このオプションはシステム全体に適用され、マウント時にのみ設定できます。
        init名前空間からの再マウントによってのみ変更できます。マウント
        オプションはinit名前空間以外のマウントでは無視されます。

  memory_recursiveprot
        memory.minとmemory.lowの保護をサブツリー全体に再帰的に適用する。
        サブツリー全体に適用する。
        リーフ cgroup への明示的な下方伝搬を必要としない。 これにより
        サブツリー内の自由競争を維持しながら、サブツリー全体を互いに保護することができる。
        サブツリー内での自由な競争を維持できる。 これはデフォルト
        これはデフォルトの動作であるべきだが、元のセマンティクスに依存したセットアップ（例えば、偽のセマンティクスを指定する）を後退させないためのマウントオプションである。
        元のセマンティクスに依存したセットアップの後退を避けるためのマウントオプションである。
        を指定するなど)。

  memory_hugetlb_accounting
        HugeTLB メモリ使用量を cgroup のメモリコントローラ全体のメモリ使用量にカウントします。
        メモリコントローラのメモリ使用量をカウントする。
        統計報告とメモリ保護のため)。これは新しい
        既存のセットアップを後退させる可能性のある新しい動作です。
        このマウントオプションで明示的にオプトインする必要があります。

        注意すべき点がいくつかあります：

        * メモリコントローラにはHugeTLBプール管理はない。
          メモリコントローラにはHugeTLBプールの管理はない。事前に割り当てられたプールは誰のものでもない。
          具体的には、新しいHugeTLBフォリオがプールに割り当てられたとき、それは
          プールに割り当てられた時、メモリコントローラの観点からは
          メモリコントローラの観点からは考慮されない。実際に使用されたとき（例えば、試合開始時など）にのみ、cgroupにチャージされる。
          に課金されるだけである。ホストのメモリ
          オーバーコミット管理は、ハードリミットを設定する際にこれを考慮する必要があります。
          ハードリミットを設定する際に考慮する必要があります。
一般的に、HugeTLBプール管理は他のメカニズム(HugeTLBコントローラなど)
          一般的に、HugeTLBプール管理は他のメカニズム（HugeTLBコントローラなど）を介して行われるべきである。
        * メモリコントローラへのHugeTLBフォリオのチャージに失敗すると、SIGBUSが発生する。
          への HugeTLB フォリオのチャージに失敗すると SIGBUS が発生する。これは、HugeTLBプールにまだ利用可能なページがある（しかし
          プールにまだ利用可能なページがある（しかし、cgroup制限にヒットし
          再要求は失敗する)。
        * メモリコントローラへのHugeTLBメモリのチャージは、メモリ保護とリクレイム動作に影響する。
          メモリ保護とリクレイムのダイナミクスに影響する。ユーザー空間のチューニング
          (ユーザー空間のチューニングは、この点を考慮する必要がある。
        * このオプションが選択されていないときに使用されたHugeTLBページは
          このオプションが選択されていないときに使用された HugeTLB ページは、（たとえ cgroup
          v2が後で再マウントされたとしても）。


プロセスとスレッドの整理
--------------------------------

プロセス
~~~~~~~~~

初期状態では、すべてのプロセスが属するルートcgroupのみが存在する。
子cgroupは、サブ・ディレクトリー::

  # mkdir $CGROUP_NAME

与えられたcgroupは、ツリー構造を形成する複数の子cgroupを持つことができる。
構造を形成する。 各 cgroup には、読み書き可能なインターフェースファイル
"cgroup.procs" があります。 読み込まれると、cgroup.procs に属するすべてのプロセスの PID が1行ごとにリストされる。
の PID が1行ごとにリストされる。 PIDは順序付けされておらず
同じPIDが複数回表示されることがある。
に移動して戻ってきたり、読み込み中に PID がリサイクルされたりすると、 同じ PID が複数回表示されることがある。

プロセスを cgroup に移行するには、その PID をターゲット cgroup の
cgroup.procs" ファイルに書き込むことで、プロセスを cgroup に移行できます。 1 回の write(2) 呼び出しで移行できるプロセスは
つの write(2) 呼び出しで移行できる。 プロセスが複数の
スレッドで構成されている場合、任意のスレッドの PID を書き込むと、 そのプロセスのすべてのスレッドが移行される。
プロセスのすべてのスレッドを移行する。

プロセスが子プロセスをフォークすると、新しいプロセスは、 フォークしたプロセスが属する
グループに生まれる。
に属する。 終了後、プロセスは、その操作時に属していた cgroup
に関連付けられたままである。
ゾンビプロセスは "cgroup.procs "に表示されないため、別のcgroupに移動することはできません。
別のcgroupに移動することはできません。

子プロセスやライブプロセスを持たない cgroup は、ディレクトリを削除することで破棄できます。
ディレクトリを削除することで破棄できます。 子プロセスがなく
子プロセスを持たず、ゾンビプロセスのみに関連付けられている
は空であるとみなされ、削除することができます。::

  # rmdir $CGROUP_NAME

"/proc/$PID/cgroup "は、プロセスのcgroupメンバーシップを一覧表示する。 レガシー
cgroup がシステムで使用されている場合、このファイルには複数行が含まれます、
階層ごとに1行ずつ。 cgroup v2 のエントリは常に
形式です。::

  # cat /proc/842/cgroup
  ...
  0::/test-cgroup/test-cgroup-nested

プロセスがゾンビになり、関連付けられていた cgroup
が削除されると、" (deleted)" が path: に追加されます::

  # cat /proc/842/cgroup
  ...
  0::/test-cgroup/test-cgroup-nested (deleted)

スレッド
~~~~~~~

cgroup v2 は、コントローラのサブセットでスレッドの粒度をサポートし、以下のような使用ケースをサポートします。
スレッド粒度をサポートします。
をサポートします。 デフォルトでは
プロセスのすべてのスレッドは同じ cgroup に属します。
ドメインとして機能します。
リソース・ドメインとしても機能します。 スレッドモードでは、スレッドをサブツリーに分散させることができます。
サブツリーに分散させることができます。

スレッドモードをサポートするコントローラはスレッドコントローラと呼ばれます。
そうでないものはドメインコントローラと呼ばれる。

スレッド化されたcgroupをマークすると、スレッド化されたcgroupとして親のリソースドメインに参加します。
のリソースドメインに参加します。 親は別のスレッド
リソースドメインがさらに上の階層にある別のスレッドcグループである可能性があります。 ルート
スレッド化されたサブツリーのルート、つまり、スレッド化されていない最も近い先祖を
スレッドドメインまたはスレッドルートと呼ばれます。
サブツリー全体のリソースドメインとして機能する。

スレッドサブツリー内部では、プロセスのスレッドを異なる
スレッド化されたサブツリーの内部では、プロセスのスレッドは異なるcgroupに置くことができ、内部プロセスなしという制約を受けません。
スレッドコントローラは、リーフでないcグループで有効にできます。
で有効にすることができます。

スレッド化されたドメインcgroupは、サブツリーのすべてのドメインリソース
サブツリーのすべてのドメインリソースを消費するので、サブツリー内にプロセスがあろうとなかろうと
リソース消費を持っているとみなされ
スレッド化されていない子cgroupを持つことはできません。 なぜなら
ルート cgroup は内部プロセスの制約を受けないため、スレッドドメインと
スレッドドメインとしてもドメイン cgroup の親としても機能します。

cgroupの現在のオペレーションモードまたはタイプは
「cgroup.type」ファイルに表示される。
ドメインであるか、スレッドサブツリーのドメインとして機能するドメインであるか、 スレッドcgroupであるかを示す、
またはスレッドcgroupであるかを示す。

作成時、cgroupは常にドメインcgroupであり、「threaded」と記述することで
cgroup.type」ファイルに「threaded」と記述することでスレッド化できる。 この場合
操作は単一方向::

  # echo threaded > cgroup.type

一度スレッド化されると、cgroupを再びドメインにすることはできない。 スレッドモードを有効にするには
スレッドモードを有効にするには、以下の条件を満たす必要があります。

- cgroupが親のリソースドメインに参加する。 親が有効な（スレッド化された）ドメインか、スレッド化されたcgroupでなければならない。

- 親がスレッド化されていないドメインである場合、ドメインコントローラーが 有効になっていないか、ドメインチルドレンが設定されていないこと。
  コントローラーが有効になってはならない。 ルートは  はこの条件から除外される。

トポロジー的には、cgroupは無効な状態になる可能性がある。 次のようなトポロジーを
以下のトポロジーを考える::

  A (threaded domain) - B (threaded) - C (domain, just created)

Cはドメインとして作成されるが、子ドメインをホストできる親に接続されていない。
Cはドメインとして作成されるが、子ドメインをホストできる親に接続されていない。 Cはスレッド化されるまで使用できない。
スレッド化されるまで使用できない。 "cgroup.type "ファイルは、このような場合に "domain (invalid) "と報告する。
と報告される。 無効なトポロジーのために失敗するオペレーションでは
EOPNOTSUPP が errno として使用される。

ドメインcgroupは、その子cgroupの1つがスレッド化またはスレッド化されると、スレッドドメインになる。
cgroupがスレッド化されるか、スレッドコントローラーが
"cgroup.subtree_control "ファイルでスレッドコントローラーが有効になる。
スレッド化されたドメインは、条件が整うと通常のドメインに戻る。
をクリアする。

読み込まれると、"cgroup.threads "には、cgroup内のすべてのスレッドIDのリストが 含まれる。
のスレッド ID のリストが含まれる。 操作がプロセス単位ではなくスレッド単位であることを除けば
であることを除けば、"cgroup.threads" は "cgroup.threads" と同じフォーマットで
cgroup.procs" と同じように動作します。 "cgroup.threads "は、"cgroup.procs "と同じフォーマットで同じように動作します。
同じスレッドドメイン内のスレッドのみを移動できるため、どのcgroupにも書き込めますが、その操作は限定されます。
スレッドドメイン内でしかスレッドを移動できないため、その操作は各スレッドサブツリー内に限定される
サブツリー内に限定される。

スレッドドメインcgroupは、サブツリー全体のリソースドメインとして機能する。
サブツリー全体のリソースドメインとして機能する、
すべてのプロセスはスレッドドメインcgroup内にあると見なされる。
スレッドドメインcgroup内の "cgroup.procs "には、サブツリー内のすべてのプロセス
サブツリー内のすべてのプロセスのPIDが含まれており、サブツリー内では読めない。
ただし、"cgroup.procs" はサブツリーのどこからでも書き込むことができる。
に書き込むことで、一致するプロセスのすべてのスレッドを cgroup に移行できます。

スレッドサブツリーで有効にできるのは、スレッドコントローラだけです。 スレッドサブツリー内で
スレッドサブツリー内でスレッドコントローラを有効にすると、スレッドコントローラのみが
に関連するリソース消費のみを考慮し、制御します。
cgroupとその子孫のスレッドに関連するリソース消費のみを考慮し、制御します。 特定のスレッドに
スレッドドメインcgroupに属します。

スレッド化されたサブツリーは、内部プロセスの制約を受けないので
スレッドサブツリーは、内部プロセスの制約から免除されるため、スレッドコントローラは
を処理できなければならない。 各スレッドコントローラは、このような競合をどのように処理するかを定義する。

現在、以下のコントローラがスレッド化され、有効にできます。
を有効にできます::

- cpu
- cpuset
- perf_event
- pids

[未設定通知
--------------------------

各非ルート cgroup には「cgroup.events」ファイルがあり、その中には
「populated" フィールドがあります。
ライブプロセスがあるかどうかを示す "populated" フィールドがあります。 にライブプロセスがない場合、値は 0 です。
ポーリングと [id]notify イベントがトリガーされます。
イベントがトリガーされます。 これは例えばすべてのプロセスが終了した後にクリーンアップを開始する場合などに使用できる。
サブ階層のすべてのプロセスが終了した後にクリーンアップを開始する場合などに使用できる。 入力された状態の更新と
通知は再帰的である。 次のようなサブ階層を考えてみよう。
ここで、括弧内の数字は、各cgroupのプロセス数の数を表します。::

  A(4) - B(0) - C(1)
              \ D(0)

A、B、Cの "populated "フィールドは "1 "になり、Dは "0 "になる。
Cの1つのプロセスが終了すると、BとCの "populated "フィールドは "0 "に反転する。
ファイル変更イベントが両方のcgroupの「cgroup.events」ファイルに生成される。
ファイルに生成される。

コントローラーの制御
-----------------------

有効化と無効化
~~~~~~~~~~~~~~~~~~~

各cgroupには "cgroup.controllers "ファイルがあります。
があります::

  # cat cgroup.controllers
  cpu io memory

デフォルトではコントローラは有効になっていない。 コントローラは、「cgroup.subtree_control」ファイルに
cgroup.subtree_control "ファイルに書き込むことで有効/無効にできます::
  # echo "+cpu +memory -io" > cgroup.subtree_control

コントローラは、「cgroup.controllers」ファイルに書き込むことで、有効化および無効化できる。
のみを有効にできる。 上記のように複数の操作が指定された場合、それらはすべて成功または失敗する。
が成功または失敗します。 同じコントローラに対して複数の操作を指定した場合
に複数の操作を指定した場合は、最後の操作が有効になる。

cgroup 内のコントローラを有効にすると、その直下の子グループへの対象 リソースの分配が制御されます。
を制御することを示します。
以下のサブ階層を考えてみましょう。 有効なコントローラを括弧内に示します。::
  A(cpu,memory) - B(memory) - C()
                            \ D()

Aは "cpu "と "memory "を有効にしているので、Aは子階層へのCPUサイクルと メモリの配分を制御する。
Bは "memory "を有効にしているが、"CPU "は有効にしていない。
Bは "CPU "ではなく "memory "が有効なので、CとDはCPUサイクルで自由に競争する。
サイクルで自由に競争するが、Bが使用できるメモリの分割は制御される。

コントローラは、cgroupの子グループへの対象リソースの分配を制御するため、コントローラを有効にすると、子cgroupにコントローラのインターフェイスファイルが作成されます。
上記の例では、Bで「cpu」を有効にすると、「cpu.を有効にすると、「cpu.D.  同様に、Bで "memory "を無効にすると、"memory." 
接頭辞のコントロー ラインターフェイスファイルがCとDから削除される。
コントローラインターフェイスファイルは、"cgroup.「で始まらないコントローラインターフェイスファイルは、
cgroup自体ではなく、親が所有することになります。

トップダウンの制約
~~~~~~~~~~~~~~~~~~~

リソースはトップダウンで分配される。
リソースはトップダウンで配布されます。
のみリソースを配布できます。 つまり、ルート以外の「cgroup.subtree_control」ファイル
には、親の
"cgroup.subtree_control "ファイルで有効になっているコントローラのみを含むことができます。 コントローラは、以下の場合にのみ有効にできる。
コントローラを有効にできるのは、親がそのコントローラを有効にしている 場合のみです。コントローラを無効にすることはできません。


内部プロセスの制約なし
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

非ルートcグループは、子グループにドメインリソースを配布できます。
にドメインリソースを配布することができます。 言い換えると
プロセスを持っていないドメインcgroupだけが、ドメインコントローラーを 「cgroup.
cgroup.subtree_control」ファイルでドメインコントローラーを有効にできる。

これにより、ドメインコントローラーが有効になっている階層のを見るとき、プロセスは常にリーフ上にのみ存在する。
これは、子cgroupが親の内部プロセスと競合する状況を排除する。

ルートcグループはこの制限から除外される。 ルートにはプロセスと匿名リソース消費が含まれ、他のcグループと関連付けることができない。
他のどのcグループとも関連付けることができず、ほとんどのコントローラから特別な扱いを受ける必要があります。
コントローラから特別な扱いを受ける必要があります。 ルートcグループのリソース消費をどのように管理するかは、各コントローラ次第です。
のリソース消費をどのように管理するかは、各コントローラ次第です。コントローラの章の非規範情報セクションを参照してください)。

cgroupの「cgroup.subtree_control」に有効なコントローラがない場合、制限は邪魔にならないことに注意してください。 
これはの子グループを作成できないため、これは重要です。
cgroupのリソース配分を制御するには、「cgroup.subtree_control」でコントローラを有効にする前に、
子グループを作成して、すべてのプロセスを子グループに転送する必要があります。
ファイルでコントローラを有効にします。

委任
----------

委任のモデル
~~~~~~~~~~~~~~~~~~~

cグループは2つの方法で委譲できる。 1つ目は、ディレクトリとそのディレクトリとその「cgroup.procs」、
「cgroup.threads」、および「cgroup.subtree_control」ファイルの書き込みアクセス権をユーザーに付与します、
「cgroup.subtree_control」ファイルの書き込みアクセス権を付与します。次に、「nsdelegate」
マウントオプションが設定されている場合、自動的にcgroup ネームスペースに自動的に追加されます。

指定されたディレクトリのリソース制御インターフェースファイルは親のリソースの配布を制御するため、デリゲートは
はそれらへの書き込みを許可されるべきではありません。 最初の方法ではこれらのファイルへのアクセスを許可しないことで
達成されます。 2番目の方法ではカーネルは、"cgroup.procs "および「を除くすべてのファイルへの書き込みを拒否します。

最終結果は、両方のデリゲーションタイプで同等です。 委任されると委譲されると、ユーザーはそのディレクトリの下にサブ階層を構築できます、
親から受け取ったリソースをさらに分配することができます。
すべてのリソースコントローラの制限やその他の設定は階層化されており
親が課すリソース制限から逃れることはできません。


現在のところ、cgroup はデリゲートされたサブ階層内のcgroup の数やデリゲートされたサブヒエラルキーのネストの深さに制限はありません、
将来的には明示的に制限される可能性があります。


委譲の包含
~~~~~~~~~~

委譲されたサブ階層は、プロセスが以下の意味で含まれます。
という意味で含まれます。

より権限の低いユーザへの委任の場合、これは以下のようにして達成される。
非 root euid を持つプロセスに以下の条件を要求する。
PID を "cgroup.procs" ファイルに書き込むことで、ターゲットプロセスを cgroup にマイグレートする。
"cgroup.procs "ファイルに書き込みます。

- ライターが「cgroup.procs」ファイルへの書き込みアクセス権を持っていること。

- ライターは、ソースとデスティネーションの共通の祖先の「cgroup.procs」ファイルへの書き込みアクセス権を持っている必要があります。
  ファイルへの書き込みアクセス権を持っている必要があります。

上記の2つの制約により、デリゲートは、デリゲートされたサブヒエラルキーの中で自由に
委任されたサブ階層内では自由にプロセスを移行することができますが、サブ階層外からは
から取り込んだり、サブ階層外に押し出したりすることはできない。

例として、cグループC0とC1が以下のように委譲されたとします。
ユーザー U0 が C00 を作成し、C0 の下に C01、C1 の下に C10 を作成したとします。
C0 と C1 の下にあるすべてのプロセスは U0 に属している。::


  ~~~~~~~~~~~~~ - C0 - C00
  ~ cgroup    ~      \ C01
  ~ hierarchy ~
  ~~~~~~~~~~~~~ - C1 - C10

また、U0が現在C10にあるプロセスのPIDを "C00/cgroup.procs "に書き込みたいとする。
C00/cgroup.procs」に書き込みたいとする。 U0はこのファイルへの書き込みアクセス権を持っている。
ファイルへの書き込みアクセス権を持っている。
の共通の祖先は、デリゲーションのポイントより上にあり、U0 はそのは「cgroup.procs」ファイルへの
書き込みアクセス権を持っていないため、書き込みはは-EACCESで拒否される。

ネームスペースへの委譲の場合、封じ込めは、ソースとデスティネーションの両方の
名前空間への委譲では、ソースcgroupと宛先cgroupの両方がネームスペースから到達可能である必要があります。
どちらかがに到達できない場合、移行は -ENOENT で拒否されます。

ガイドライン
----------

一度整理して制御する
~~~~~~~~~~~~~~~~~

cgroups をまたがるプロセスの移行は、比較的高価な操作である。
であり、メモリーなどのステートフルなリソースはプロセスと共に移動されない。
プロセスと共に移動されない。 これは明確な設計上の決定です。
マイグレーションと様々なホットパスの間には、同期コストという点で本質的なトレードオフが存在することが多いからです。
同期コストという点で、マイグレーションとさまざまなホットパスの間には本質的なトレードオフが存在することが多いためです。

そのため、異なるリソース制限を適用するために、cgroup間で頻繁にプロセスをマイ グすることは推奨されません。
プロセスを頻繁に移行することは推奨されません。ワークロードは、システムの論理およびリソース構造に従って、
cgroup に割り当てる必要があります。リソース構造に従ってcgroupに割り当てる必要があります。
リソース配分の動的な調整はインターフェイスファイルでコントローラ構成を変更することで、リソース配分を動的に調整できます。


名前の衝突を避ける
~~~~~~~~~~~~~~~~~~~~~

cgroupとその子cgroupのインターフェースファイルは同じディレクトリを占有します。
を作成することができます。

すべてのcgroupコアのインターフェイスファイルの先頭には「cgroup.」が付き、各コントローラの
インターフェイスファイルの先頭には「cgroup.」が付きます。
ドットが先頭に付きます。 コントローラ名は、小文字のアルファベットとコントローラ名は、
小文字のアルファベットと'_'で構成されるが、'_'で始まることはない。
文字として使用できます。 また、インターフェイスのファイル名はまた、インターフェイスファイル名は、ジョブ、
サービス、スライスなど、ワークロードを分類する際によく使われる用語で始まったり終わったりすることはない。

cgroupは名前の衝突を防ぐために何もしません。ユーザーの責任です。

資源分配モデル
============================

cgroup コントローラは、リソースの種類と想定されるユースケースに応じて、 いくつかのリソース分配スキームを実装します。
このセクションではでは、使用されている主なスキームと期待される動作について説明します。

ウェイト
-------

親のリソースは、すべてのアクティブな子のウェイトを合計して分配されます。
の重みを合計し、その合計に対する重みの比率にマッチする
を与える。 分配に参加するのは資源を利用できる子だけが分配に参加するので、これは
は仕事を節約することになる。 動的な性質のため、このモデルは通常に使用される。

すべての重みは[1, 10000]の範囲で、デフォルトは100です。 り
これにより、直感的な粒度にとどまりながら、双方向に対称的な乗法バイアスをかけることができる。
直感的な範囲に収まる。

ウェイトが範囲内にある限り、すべてのコンフィギュレーションの組み合わせが有効であり
を拒否する理由はない。

"cpu.weight "は、アクティブな子どもたちにCPUサイクルを比例配分する。このタイプの例である。

.. _cgroupv2-limits-distributor:

リミット
------

子プロセスは設定されたリソース量までしか消費できません。
リミットはオーバーコミットされる可能性があります。
親が利用できるリソースの量を超えることがあります。

リミットは [0, max] の範囲で、デフォルトは "max" です。

リミットはオーバーコミットされる可能性があるため、すべての設定の組み合わせが有効です。
プロセスの移行を拒否する理由はない。

「io.max」は、cgroup が IO デバイスで消費できる最大 BPS および/または IOPS を制限します。
このタイプの例です。

.. _cgroupv2-protections-distributor:

プロテクション
-----------

cgroup は設定されたリソース量まで保護されます。
保護はハード保証またはベストエフォートソフト境界です。 プロテクションはオーバーコミットすることもできます。
親が利用可能な量までしか、子の間で保護されない。

プロテクションは[0, max]の範囲で、デフォルトは0です。

プロテクションはオーバーコミットすることができるので、すべてのコンフィギュレーションの組み合わせを拒否する理由はありません。

"memory.low "はベストエフォート型メモリ保護を実装しており、このタイプの例である。

割り当て
-----------

cグループはある有限のリソースのある量を独占的に割り当てられる。割り当てをオーバーコミットすることはできません。
子グループの割り当ての合計が、親グループが使用できるリソースの量を超えることはできません。

割り当ての範囲は [0, max] で、デフォルトは 0 です。

アロケーションはオーバーコミットできないので、いくつかのコンフィギュレーション
の組み合わせは無効であり、拒否されるべきです。 またリソースがプロセスの実行に必須である場合、
プロセスのマイグレーションは拒否される可能性があります。

"cpu.rt.max "はリアルタイムスライスをハードアロケートしますが、これはこのタイプの例です。

インターフェース・ファイル
===============

フォーマット
------

すべてのインターフェース・ファイルは、可能な限り以下のいずれかの形式でなければならない。
可能な限り::


  New-line separated values
  (when only one value can be written at once)

	VAL0\n
	VAL1\n
	...

  Space separated values
  (when read-only or multiple values can be written at once)

	VAL0 VAL1 ...\n

  Flat keyed

	KEY0 VAL0\n
	KEY1 VAL1\n
	...

  Nested keyed

	KEY0 SUB_KEY0=VAL00 SUB_KEY1=VAL01...
	KEY1 SUB_KEY0=VAL10 SUB_KEY1=VAL11...
	...


書き込み可能なファイルの場合、書き込みのフォーマットは、一般的に、読み込みのフォーマットと同じであるべきである。
しかし、コントローラは、後のフィールドの省略を許可したり、 一般的な使用例に対して制限されたショートカットを実装したりすることができる。

フラットファイルでもネストされたキー付きファイルでも、一度に書き込めるのは単一のキーの値だけです。
の値のみを一度に書き込むことができます。 ネストされたキー付きファイルでは、サブキー・ペア
は任意の順番で指定することができ、すべてのペアを指定する必要はない。

規則
-----------

- 1つの機能の設定は1つのファイルに含める。

- ルート cgroup はリソース制御の対象外とする。
  リソース制御インターフェイスファイルを持つべきでない。

- デフォルトの時間単位はマイクロ秒です。 異なる単位を使用する場合は
  を使用する場合は、明示的な単位サフィックスが必要です。

- パート・パー数量は、少なくとも2桁の小数部を持つパーセンテージの10進数を使用すべきである。
  を使用する。

- コントローラが、重量ベースのリソース分配を実装する場合、そのインターフ ェースファイルは、「weight」という名前でなければならない。
  インターフェイスファイルの名前は「weight」とし、範囲は[1、10000]の範囲で指定する。 この値は
  この値は、双方向に十分かつ対称的なバイアスを許容し、直感的に使用できるように選択される。
  デフォルトは100%）。

- コントローラが絶対的なリソース保証および/または制限を実装する場合
  制限を実装している場合、インターフェイスファイルの名前は "min" および "max" にする必要がある。
  という名前を付けなければならない。 コントローラがベストエフォートリソース
  を実装している場合、インターフェイスファイルの名前はそれぞれ
  および "high "とする。

  上記の4つの制御ファイルでは、特別なトークン "max "を使用しなければならない。

- 設定に設定可能なデフォルト値とキーによる特定の  オーバーライドがある場合、デフォルトのエントリーは "default "をキーとし
  ファイルの最初のエントリとして表示されます。

  デフォルト値は、"default $VAL "または"$VAL "と記述することで更新できます。

  特定のオーバーライドを更新するために書き込む場合、オーバーライドの削除を示す値として「default」を使用できます。
  オーバーライド・エントリを値として使用するオーバーライド・エントリは、読み取り時に表示されないようにする必要があります。

  例えば、メジャー：マイナー・デバイス番号でキー設定された設定は、整数値で次のようになります。
  をキーとする設定は、以下のようになります。::

    # cat cgroup-example-interface-file
    default 150
    8:0 300

  デフォルト値は以下の方法で更新できる::

    # echo 125 > cgroup-example-interface-file

  または::

    # echo "default 125" > cgroup-example-interface-file

  オーバーライドは以下の方法で設定され::
  
    # echo "8:16 170" > cgroup-example-interface-file

 以下の方法で解除される::

    # echo "8:0 default" > cgroup-example-interface-file
    # cat cgroup-example-interface-file
    default 125
    8:16 170

- あまり頻度の高くないイベントについては、イベントのキーと値のペアをリストしたインターフェイス・ファイル
  "events "を作成する必要がある。
  通知可能なイベントが発生するたびに、ファイル変更イベント
  が生成されなければならない。

コア・インターフェース・ファイル
--------------------

すべての cgroup コアファイルには "cgroup" がプレフィックスとして付きます。

  cgroup.type
	非ルートの
	に存在する読み書き可能な単一値ファイルです。

	読み込まれると、cgroup の現在のタイプを示します。
	の現在のタイプを示します。

	- domain" ： 通常の有効なドメイン cgroup。

	- "domain threaded" : スレッドサブツリーのルートとして機能するスレッドドメイン cgroup。
          スレッドサブツリーのルートとして機能する。

	- "domain invalid" ：無効なドメイン： 無効な状態のcgroup。
	  コントローラーが有効になっていない。 しかし
	  スレッド cgroup になることは許可される。

- threaded" : スレッドサブツリーのメンバーであるスレッドcグループ。
          スレッド化されたサブツリーのメンバーであるスレッド化された

	スレッド化されたサブツリーのメンバーであるスレッド化された cgroup。
	"threaded "をこのファイルに記述することで、cgroup をスレッド化できます。

-  cgroup.procs
	すべての cgroup に存在する読み書き可能な改行区切りの値ファイル。
	すべての cgroup に存在します。

	読み込まれると、cgroup に属するすべてのプロセスの PID が 1 行ごとにリストされます。
	プロセスの PID を 1 行ごとにリストします。 PID には順序はなく
	同じ PID が複数回表示されることがあります。
	プロセスが別の cgroup に移動して戻ってきたり、 読み込み中に PID がリサイクルされたりすると、同じ PID が複数回表示されることがある。

	PIDは、そのPIDに関連するプロセスをcgroupに移行するために書き込むことができる。
	ライターは、以下のすべての条件に一致する必要がある。
	
	- 「cgroup.procs」ファイルへの書き込みアクセス権を持っている。

	- 移行元と移行先の共通の先祖の「cgroup.procs」ファイルへの書き込みアクセス権を持っている。
	  の "cgroup.procs "ファイルへの書き込みアクセス権を持っていること。

	サブ階層をデリゲートする場合、このファイルへの書き込みアクセス権
	への書き込みアクセス権を付与する必要があります。

        スレッド化されたcgroupでは、このファイルの読み取りはEOPNOTSUPPで失敗する。
	書き込みはサポートされ、プロセスの各スレッドを cgroup に移動します。

  cgroup.threads
	に存在する読み書き可能な改行区切りの値ファイル。
	すべての cgroup に存在します。

	読み込まれると、cgroup に属するすべてのスレッドの TID が 1 行ごとにリストされます。
	すべてのスレッドの TID を一覧表示します。 TID は順序付けされておらず
	同じ TID が複数回表示されることがあります。
	スレッドが別のcgroupに移動して戻ってきたり、読み込み中にTIDがリサイクルされたりすると、同じTIDが複数回表示されることがある。
	読み取り中にリサイクルされた場合、同じTIDが複数回表示されることがある。

	TIDを書き込むことで、そのTIDに関連するスレッドをcgroupに移行させることができる。
	TIDをcgroupに移行するために書き込むことができる。 ライターは、次のすべての条件に一致する必要がある。
	次の条件をすべて満たす必要がある。

	- cgroup.threads」ファイルへの書き込みアクセス権を持っていること。

	- スレッドが現在所属している cgroup が、移行先の cgroup と同じリソースドメインにあること。
          同じリソースドメインにあること。

	- ソースと宛先の共通の祖先の "cgroup.procs" ファイルへの書き込みアクセス権を持っていること。
	  ファイルへの書き込みアクセス権を持っている必要があります。

	サブ階層をデリゲートする場合、このファイルへの書き込みアクセス権
	への書き込みアクセス権も付与する必要があります。

cgroup.controllers
	すべての
	ファイルです。

	すべての cgroup に存在する、スペース区切りの値ファイルです。
	の一覧を表示します。 コントローラは順序付けされていません。

  cgroup.subtree_control
	すべての cgroup に存在する読み書き可能なスペース区切りの値ファイル。
	ファイル。 最初は空です。

	読み込むと、スペースで区切られたコントローラのリストが表示されます。
	の一覧が表示されます。
	cgroup からその子グループへのリソース配布を制御するために有効になっているコントローラの一覧を表示します。

	スペースで区切られたコントローラのリストには、先頭に '+' または '-' を付けます。
	を前につけると、 コントローラを有効にしたり無効にしたりできます。 コントローラ
	を前につけるとコントローラが有効になり、 「-」をつけると無効になります。
	は無効にする。 コントローラがリストに複数表示される場合は、最後のものが有効になる、
	が有効です。 複数の有効 / 無効を指定すると、すべてが成功するか、すべてが失敗します。
	操作が複数指定された場合、すべてが成功するか、すべてが失敗します。

  cgroup.events
	非ルートのcgroupに存在する読み取り専用のフラットキーファイル。
	以下のエントリが定義されています。 以下のエントリが定義されています。
	このファイルの値が変更されると、ファイル
	変更イベントを生成します。

	  populated
	        cgroupまたはその子孫にライブプロセスがある場合は1。そうでなければ 0。
	  frozen	
		cgroup がフリーズしている場合は 1、そうでない場合は 0。

  cgroup.max.descendants
	読み書き可能な単一値ファイル。 デフォルトは "max"。

	子孫 cgroups の最大許容数。
	実際の子孫の数が等しいか、それより大きい場合、
	階層内に新しい cgroup を作成しようとすると失敗します。

  cgroup.max.depth
	読み書き可能な単一値ファイル。 デフォルトは "max"。

	現在の cgroup より下にある、最大許容降下深度。
	実際の降下深度が等しいか大きい場合、
	新しい子 cgroup を作成しようとすると失敗します。

  cgroup.stat
	読み取り専用のフラットキーファイルで、以下のエントリがあります：

	  nr_descendants
		可視の子孫 cgroup の総数。

  nr_dying_descendants
	死につつある子孫 cgroup の総数。cgroup はユーザーによって削除されると
	になります。cgroup は完全に破棄されるまでの未定義の時間 (システム負荷に依存する可能性があります)

	プロセスはいかなる状況でも、瀕死の cgroup に入ることはできません、
	瀕死の cgroup は復活できません。

	死にかけの cgroup は、システムリソースを消費することができます。
	リミットを超えない範囲でシステムリソースを消費できます。

  cgroup.freeze
	非 root cgroup に存在する読み書き可能な単一値ファイル。
	許可される値は「0」と「1」です。デフォルトは「0」です。

        ファイルに "1 "を書き込むと、そのcgroupとすべての子孫のcgroupがフリーズする。
	これは、所属するすべてのプロセスは停止され、cgroup が明示的に凍結解除されるまで実行されません。
	凍結が解除されるまで実行されない。cgroup の凍結には時間がかかることがあります。
	このアクションが完了すると、cgroup.events制御ファイルの「frozen」値
	の "frozen "値は "1 "に更新され、対応する通知	が発行されます。

	cgroup は自身の設定、または祖先 cgroup の設定によって凍結できます。
	によって凍結できます。先祖の cgroup のいずれかが凍結されると、その
	cgroup はフリーズしたままになります。

	フリーズした cgroup 内のプロセスは、fatal シグナルで強制終了できる。
	また、フリーズした cgroup に出入りすることもできます。
	ユーザーによる明示的な移動か、fork() で cgroup の凍結が競合した場合である。
	プロセスがフリーズした cgroup に移動すると、停止する。プロセスが
	プロセスがフリーズした cgroup から移動されると、実行状態になります。

	cgroup の凍結ステータスは、cgroup ツリーの操作には影響しません：
	フリーズした（空の） cgroup を削除することも、新しいサブグループを作成することもできます。
	新しいサブグループを作成することもできます。

cgroup.kill
	非ルートのcgroupに存在する書き込み専用の単一値ファイル。
	許可される値は「1」のみです。

	ファイルに「1」を書き込むと、その cgroup とすべての子孫 cgroup が kill されます。
	が強制終了される。つまり、影響を受ける cgroup
	ツリーにあるすべてのプロセスが SIGKILL で強制終了されることを意味します。

	cgroup ツリーを強制終了すると、同時フォークが適切に処理され、マイグレーションから保護されます。
	マイグレーションから保護されます。

	スレッド化された cgroup では、このファイルの書き込みは EOPNOTSUPP で失敗します。
	つまり、スレッドグループ全体に影響します。
	で失敗します。

  cgroup.pressure
	読み書き可能な単一値ファイルで、許可される値は "0" と "1" です。
	デフォルトは "1 "である。

	このファイルに "0" を書き込むと、cgroup PSI アカウンティングが無効になる。
	このファイルに「1」を書き込むと、 cgroup PSI アカウンティングが再度有効になる。

        この制御属性は階層的でないため、cgroup で PSI アカウンティングを無効にしたり有効にしたりしても、子孫の PSI アカウンティングには影響しない。
	また、ルートから祖先を経由して有効にする必要もない。

	この制御属性が存在する理由は、PSI が各 cgroup の失速を個別に計算し、それを集計するためである。
	このため、ワークロードによっては、次のような場合に無視できないオーバヘッ ドが発生する可能性があります。
	この場合、この制御属性を使用して、非リーフ cgroup のPSI アカウンティングを無効化することができる。
	
  irq.pressure
	読み書き可能なネストされたキーファイル。

	IRQ/SOFTIRQ の圧力ストール情報を示す。以下を参照のこと。
	詳細は :ref:`Documentation/accounting/psi.rst <psi>` を参照のこと。

コントローラ
===========

.. _cgroup-v2-cpu:

CPU
---
cpu」コントローラーは、CPUサイクルの配分を調整する。 この
このコントローラは、通常のスケジューリングポリシーではウェイトモデルと絶対帯域幅制限モデル
を実装している。

上記のすべてのモデルにおいて、サイクル分布は時間ベースのみで定義される。
で定義され、タスクが実行される頻度は考慮されない。
(オプションの)利用率クランピングサポートにより、スケジュー ルガバナーであるschedutil
cpufreqガバナーは、CPUが常に提供すべき最小の希望頻度をヒントにすることができます。
CPUが提供すべき最小希望頻度、およびCPUが超えてはならない最大希望頻度について、schedutil cpufreqガバナーにヒントを与えることができる。
を超えてはならない。

警告: cgroup2 はまだリアルタイムプロセスの制御をサポートしていません。
cpuコントローラは、すべてのRTプロセスがルートcgroupにある場合にのみ有効にできます。
にある場合のみ有効です。 システム管理ソフトウェアがすでに
システム管理ソフトウェアが、システムブートプロセス中にRTプロセスを非ルートcgroupsに配置している場合があります。
に配置されている場合があり、cpu コントローラを有効にするには、これらのプロセスをルート cgroup
に移動する必要がある場合があります。

CPUインターフェースファイル
~~~~~~~~~~~~~~~~~~~~~~

時間の単位はすべてマイクロ秒です。

  cpu.stat
	読み取り専用のフラットキーファイル。
	このファイルは、コントローラが有効であるかどうかに関係なく存在する。

	常に以下の3つの統計情報を報告する：

	- usage_usec
	- user_usec。
	- system_usec

	コントローラが有効な場合は、以下の5つの統計情報を報告します：

	- nr_periods
	- nr_throttled
	- スロットル
	- nr_bursts
	- バースト秒数

  cpu.weight
	非ルートのcgroups に存在する読み書き可能な単一の値ファイル。 デフォルトは "100 "です。

	非アイドルグループ(cpu.idle = 0)の場合、ウェイトは	の範囲 [1, 10000] になります。

	cグループがSCHED_IDLE（cpu.idle = 1）に設定されている場合、ウェイトは0と表示されます、
	
  cpu.weight.nice
	非ルートの
	cgroups に存在する読み書き可能な単一の値ファイル。 デフォルトは "0" です。

	nice 値は [-20, 19] の範囲である。

	このインターフェイスファイルは
	"cpu.weight" の代替インターフェイスであり、 nice(2) で使用されるのと同じ値を使って
	nice(2) で使用されるのと同じ値を使用して、 重みの読み込みと設定を可能にする。 範囲が小さく
	粒度は nice の値の方が粗いので、読み込まれる値はが現在の重みに最も近い近似値となります。

  cpu.max
	非 root cgroup に存在する読み書き可能な 2 つの値ファイル。
	デフォルトは "max 100000"。

	帯域幅の上限。 以下の形式::

	  $MAX $PERIOD

	という形式である。MAXの "max "は、制限がないことを示す。 もし
	が1つだけ書かれた場合、$MAXは更新される。

  cpu.max.burst
	非ルートに存在する読み書き可能な単一値ファイル。
	ファイル。 デフォルトは "0" です。

	範囲 [0, $MAX] のバースト。

  cpu.pressure
	読み書き可能なネストされたキーファイル。

	CPUの圧力ストール情報を示す。参照
	詳細は :ref:`Documentation/accounting/psi.rst <psi>` を参照してください。

  cpu.uclamp.min
        非 root cgroup に存在する読み書き可能な単一値ファイル。
        デフォルトは "0"、つまり利用率のブーストはありません。

        要求された最小利用率（保護）をパーセンテージで指定します。
        有理数、例えば 12.34% の場合は 12.34。

        このインターフェイスでは、sched_setattと同様に、最小利用率クランプ値
        sched_setattr(2) と同様です。この最小利用率
        値は、タスク固有の最小利用率クランプに使用されます。

        要求された最小利用率（プロテクション）は、常に、最大利用率（プロテクション）の現在値である
        最大利用率 (制限) の現在の値、すなわち
        すなわち `cpu.uclamp.max` である。

  cpu.uclamp.max
        非ルートcグループに存在する読み書き可能な単一値ファイル。
        デフォルトは "max "である。

        要求された最大利用率（制限）をパーセンテージの合理的な
        例えば、98.76% の場合は 98.76。

        このインターフェースは、sched_setattと同様に、最大利用率クランプ値の読み取りと設定を可能にする。
        sched_setattr(2) と同様の値の読み込みと設定が可能です。この最大利用率
        値は、タスク固有の最大利用率クランプに使用される。

  cpu.idle
	非 root cgroup に存在する読み書き可能な単一値ファイル。
	デフォルトは 0 である。

	これは、タスクごとの SCHED_IDLE スケジューポリシーの cgroup アナログである。
	この値を 1 に設定すると、cgroup のスケジューリングポリシーが
	cgroup のスケジューリングポリシーが SCHED_IDLE になります。cgroup 内のスレッドは、各自の相対的な優先順位を保持します。
	の中のスレッドはそれぞれの相対的な優先順位を保持しますが、 cgroup 自体はピアに対して非常に低い優先順位として扱われます。
	として扱われます。

メモリ
------

メモリコントローラーは、メモリの分配を調整する。 メモリは
ステートフルであり、制限モデルと保護モデルの両方を実装している。 そのため
メモリ使用量と再生圧力の間の絡み合いと、メモリのステートフルな性質のため
メモリのステートフルな性質により、分配モデルは比較的複雑である。

完全に防水というわけではないが、与えられた
cgroupによる主要なメモリ使用はすべて追跡される。
説明され、合理的な範囲で制御される。 現在
現在、以下の種類のメモリ使用量が追跡されている。

- ユーザーランドメモリ - ページキャッシュと匿名メモリ。

- デントリやinodeなどのカーネルデータ構造。

- TCPソケット・バッファ。

上記のリストは、より良いカバレッジのために将来拡張される可能性がある。

メモリーインターフェースファイル
~~~~~~~~~~~~~~~~~~~~~~

メモリ量はすべてバイト単位である。 PAGE_SIZEにアライメントされていない値が書き込まれた場合
PAGE_SIZEに整列されていない値が書き込まれた場合、その値は最も近いPAGE_SIZEの倍数に切り上げられることがある。
に最も近いPAGE_SIZE倍数に切り上げられるかもしれない。

  memory.current
	非ルートの
	cgroups に存在する読み取り専用の単一値ファイル。

	cgroup およびその子孫で現在使用されているメモリの合計量。
	およびその子孫によって現在使用されているメモリの合計量です。

  memory.min
	非ルートの
	cgroups に存在する読み書き可能な単一値ファイルです。 デフォルトは "0" です。

	ハードメモリ保護。 cgroup のメモリ使用量が
	のメモリ使用量が有効な最小境界内にある場合、cgroup のメモリ
	が再要求されることはありません。もし
	保護されていない再生可能メモリがない場合、OOM キラー
	が呼び出される。有効最小境界より上（または
	を超えると、超過分に比例してページが再生される。
	オーバーエイジに比例して再生される。
	より小さなオーバーエイジに対しては、リクレイム圧力が減少する。
	有効な最小値の境界は、すべての先祖 cgroup の memory.min 値によって制限される。
	値によって制限されます。memory.min のオーバーコミットがある場合
	がある場合 (子 cgroup または cgroup が、親が許可するよりも多くの保護メモリ
	親が許可するよりも多くの保護メモリを必要とする)、各子 cgroup は
	親の保護に比例する部分を取得します。
	を下回る実際のメモリ使用量に比例する親の保護部分を取得します。

	この
	この保護下に一般的に使用可能なメモリ以上のメモリを置くことは推奨されず、常に OOM につながる可能性があります。

	メモリ cgroup にプロセスが投入されていない場合、 memory.min は無視される、
	その memory.min は無視される。

  memory.low
	root 以外の cgroup に存在する読み書き可能な単一値ファイル。
	ファイル。 デフォルトは "0" です。

	ベストエフォート型のメモリ保護。 cgroup のメモリ使用量が
	cgroup のメモリ使用量が有効な低バウンダリ内にある場合、cgroup の
	メモリは再要求されません。
	ない限り、cgroup のメモリは再要求されません。
	実効低バウンダリ（または 
	を超えると、超過分に比例してページが再要求されます。
	オーバーエイジに比例して再要求され、オーバーエイジが小さいほど再要求の圧力が減ります。
	より小さいオーバーエイジでは、リクレイム圧力が減少する。

        効果的な低さの境界は、すべての先祖のcグループのmemory.low値によって制限される。
	値によって制限されます。memory.low のオーバーコミットがある場合
	(がある場合（子 cgroup または cgroup が親の許容量よりも多くの保護メモリ
	親が許可するよりも多くの保護メモリを必要とする)、各子 cgroup は
	親の保護に比例する部分を取得します。
	を下回る実際のメモリ使用量に比例する親の保護の一部を取得します。

	一般的に使用可能なメモリよりも多くのメモリをこの
	以上のメモリをこの保護下に置くことは推奨されません。

  memory.high
	非ルートグループに存在する読み書き可能な単一値ファイル。
	cグループに存在する読み書き可能な単一値ファイル。 デフォルトは "max"。

	メモリ使用量のスロットル制限。 cgroup の使用量が
	を超えると、その cgroup のプロセスはスロットルされ
	のプロセスはスロットルされ、大きな再生プレッシャーにさらされます。

	高リミットを超えても OOM キラーは発動しません。
	極端な条件下では制限を突破することもあります。ハイ
	リミットは、外部プロセスが制限された cgroup を監視するシナリオで使用する必要があります。
	が制限された cgroup を監視し、大きな再生圧力を緩和する場合に使用される。
	圧力を緩和するために、外部プロセスが制限された

  memory.max
	非ルートグループに存在する読み書き可能な単一値ファイル。
	cグループに存在する読み書き可能な単一値ファイル。 デフォルトは "max"。

	メモリ使用量のハードリミット。 これは
	cgroup のメモリ使用量を制限する主なメカニズムです。 cgroup のメモリ使用量が
	に達すると、OOM キラーが起動します。
	が起動されます。特定の状況下では、使用量が
	を一時的に超えることがあります。

	デフォルトの設定では、OOM killer が現在のメモリを選択しない限り、 通常の 0-order のアロケーションは常に成功する。
	OOMキラーが現在のタスクを犠牲者に選ばない限り成功する。

	いくつかの種類の割り当てでは、OOMキラーが起動されない。
	呼び出し元は、別の方法で再試行したり、-ENOMEMとしてユーザー空間に戻ったり、あるいは黙ってOOMキラーを呼び出したりすることができる。
	に戻したり、ディスクのリードアヘッドのような場合には無視したりすることができる。

  memory.reclaim
	すべての cgroup に存在する書き込み専用のネストされたキー付きファイル。

	のメモリ再要求をトリガーするシンプルなインターフェイスです。
	をトリガする簡単なインターフェイスです。

	このファイルは、再要求するバイト数である 1 つのキーを受け入れます。
	現在のところ、ネストされたキーはサポートされていません。

	例::

	  echo "1G" > memory.reclaim

	このインターフェイスは、後でネストしたキーで拡張することができる。
	リクレイムの動作を設定する。例えば
	を指定する。

	カーネルはターゲットcgroupからの再要求をオーバーまたはアンダーできることに注意してください。
	から過剰または過小にリクレイムできることに注意してください。リクレイムされたバイト数が指定した量より少ない場合
	指定された量より少ない場合は、-EAGAIN が返される。

  memory.reclaim
	（このインターフェイスによってトリガーされる）プロアクティブ・リクレイムは
	メモリの圧力を示すものではないことに注意すること。そのため
	によってトリガーされるソケットメモリバランシングは、この場合通常実行されない。
	つまり、ネットワーキング層は
	つまり、ネットワーク層は memory.reclaim によって引き起こされる

  memory.peak
	非 root のcgroups に存在する読み取り専用の単一値ファイルです。

	その cgroup とその子孫で記録された最大メモリ使用量。
	の子孫に記録された最大メモリ使用量。

  memory.oom.group
	非ルートの cgroup に存在する読み書き可能な単一値ファイル。
	cgroups に存在する読み書き可能な単一値ファイル。 デフォルト値は「0」です。

	cgroup を次のように分割できないワークロードとして扱うかどうかを決定します。
	cgroup を OOM キラーによって分割不可能なワークロードとして扱うかどうかを決定します。設定すると
	設定されている場合は、cgroup またはその子孫に属するすべてのタスク
	(メモリー cgroup がリーフ cgroup でない場合) に属するすべてのタスクは、一緒に kill されるか、まったく kill されない。
	される。これは
	ワークロードの整合性を保証するために、部分的な強制終了を避けるために使用できる。

	OOM 保護（oom_score_adj を -1000 に設定）を持つタスクは例外として扱われ、決して強制終了されない。
	を持つタスクは例外として扱われ、決して強制終了されない。

        OOMキラーがあるcgroupで起動された場合、そのcgroupの外のタスクを殺すことはない。
	に関係なく、この cgroup の外のタスクを kill しない。
	memory.oom.group 値に関係なく、この cgroup の外のタスクを kill しない。

  memory.events
	非ルート cgroup に存在する読み取り専用のフラットキーファイル。
	以下のエントリが定義されています。 以下のエントリが定義されています。
	このファイルの値が変更されると、ファイル
	変更イベントを生成する。

	このファイルのすべてのフィールドは階層化されており
	イベントによって生成される可能性があることに注意してください。
	イベントが発生する可能性がある。cgroupレベルのローカル・イベントについては
	を参照してください。

	  min
		cgroup の使用率が低いにもかかわらず、メモリ圧が高いために再要求された回数。
		メモリ使用量が
		を下回っているにもかかわらず、メモリ圧力が高いために再要求された回数。 これは通常
		境界がオーバーコミットされていることを示す。
	  high
		cgroup のプロセスが、直接メモリ再要求を実行するためにスロットルされ、ルーティングされる回数。
		スロットルされ、直接メモリ再要求を実行するようにルーティングされた回数。
		された回数。 メモリ使用量が
		メモリ使用量の上限がグローバルメモリ圧力ではなく
		によって上限が設定されている cgroup では、このイベント
		の発生が予想されます。

	  max
		cgroup のメモリ使用量が最大値を超えそうになった回数。
		を超えた回数。 直接リクレイム
		が失敗すると、cgroup は OOM 状態になります。

	  OOM
		cgroup のメモリ使用量が上限に達し、割り当てが行われようとした回数。
		限界に達し、割り当てが失敗しそうになった回数。

		OOM キラーがオプションとして考慮されない場合、このイベントは発生しません。
		がオプションとして考慮されていない場合、このイベントは発生しない。
		このイベントは発生しない。

	  oom_kill
		この cgroup に属するプロセスの数。
		に属するプロセスの数。

          oom_group_kill
                グループ OOM が発生した回数。

  memory.events.local
	memory.eventsに似ているが、ファイル内のフィールドはcgroupのローカルなものである。
	つまり階層的ではありません。ファイル変更イベント
	はローカルイベントのみを反映します。

  memory.stat
	非 root cgroup に存在する読み取り専用のフラットキーファイル。

	これは、cgroup のメモリフットプリントをさまざまなメモリタイプに分解します。
	メモリのタイプ、タイプ固有の詳細、およびその他の情報に分解されます。
	メモリ管理システムの状態や過去のイベントに関するその他の情報を提供します。

	メモリ量はすべてバイト単位です。

	エントリは人間が読めるように順番に並んでおり、新しいエントリ
	が現れることもある。項目が一定の位置にあることを当てにしないでください。
	特定の値を調べるにはキーを使用する！

	エントリーにノードごとのカウンターがない場合（または
	memory.numa_stat)。タグとして'npn'(non-per-node)を使用します。
	を使用して、memory.numa_statに表示されないことを示します。

	  anon
		のような匿名マッピングで使用されるメモリ量。
		brk()、sbrk()、mmap(MAP_ANONYMOUS) などの匿名マッピングで使用されるメモリ量。

	  file
		ファイルシステムのデータをキャッシュするために使用されるメモリ量、
		tmpfs や共有メモリを含む。

	  kernel（npn）
		カーネルの総メモリ量。
		(kernel_stack、pagetables、percpu、vmalloc、slab）。
		その他のカーネルメモリの使用例も含む。

	  kernel_stack
		カーネルスタックに割り当てられたメモリ量。

	  pagetables
                ページ・テーブルに割り当てられたメモリー量。

	  sec_pagetables
		セカンダリページテーブルに割り当てられたメモリ量、
		これは現在、x86およびarm64のKVM mmu割り当てを含む。
		およびarm64でのKVM mmu割り当てが含まれます。

	  percpu (npn)
		CPUごとのカーネルデータ構造を格納するために使用されるメモリ量。
		データ構造。

	  sock (npn)
		ネットワーク転送バッファで使用されるメモリ量。

	  vmalloc (npn)
		vmap バックアップメモリに使用されるメモリ量。

	  shmem
		スワップバックされるキャッシュファイルシステムデータの量、
		tmpfs、shm セグメント、共有匿名 mmap()s など。

	  zswap
		zswap 圧縮バックエンドが消費するメモリ量。

	  zswapped
		zswap にスワップアウトされたアプリケーションメモリの量。

	  file_mapped
		mmap() でマップされたファイルシステムのキャッシュ・データ量。

	  file_dirty
		変更されたがまだディスクに書き戻されていない、キャッシュされたファイルシステムのデータ量。
		ディスクに書き戻されていない

	  file_writeback
		キャッシュされたファイルシステムのデータのうち、変更され
		現在ディスクに書き戻されている

	  swapcached
		メモリにキャッシュされているスワップ量。スワップキャッシュは
		メモリとスワップ使用量の両方に対して計算される。

	  anon_thp
		による匿名マッピングで使用されるメモリ量。
		透過的なヒュッゲページ

	  file_thp
		トランスペアレントなハゲページ

	  shmem_thp
		shm、tmpfs、共有匿名 mmap() の量。
		透過的なヒュッゲページ

	  inactive_anon、active_anon、inactive_file、active_file、unevictable
		スワップバックアップメモリとファイルシステムバックアップメモリの量、
		スワップバックアップメモリとファイルシステムバックアップメモリの量。
		ページ再生アルゴリズムが使用する内部メモリ管理リストのスワップバックアップメモリとファイルシステムバックアップメモリの量。

		これらは内部リストの状態を表すので（例えば、shmemページはanon
		メモリ管理リスト上にある)、inactive_foo + active_foo は
		fooカウンターは型ベースであり、リストベースではないからである。
		リスト・ベースではないからだ。

	  shmem_thp
		スラブ "の一部で再生可能なもの。
		デントリやinodeなど。

	  slab_unreclaimable
		スラブ "の一部。
		圧力。

	  slab (npn)
		カーネル内データ構造の格納に使用されるメモリ量。
		構造体を格納するために使用されるメモリ量。

	  workingset_refault_anon
		以前に退避された匿名ページのリフォールト数。

	  workingset_refault_file
		以前に退避されたファイルページのリフォールト数。

	  workingset_activate_anon
		すぐにアクティブ化されたリフォールトされた匿名ページの数。
		の数。

	  workingset_activate_file
		即座にアクティブにされたリフォールトされたファイルページの数。

	  workingset_restore_匿名
		として検出された、復元された匿名ページの数。
		復元された匿名ページの数。

	  workingset_restore_file
		として検出された、リストアされたファイルページの数。
		として検出されたリストアされたファイルページの数。

	  workingset_nodereclaim
		シャドウ・ノードが再要求された回数。

	  pgscan (npn)
		(非アクティブなLRUリストで)スキャンされたページの量。

	  pgsteal (npn)
		再要求されたページの量。

	  pgscan_kswapd (npn)
		kswapd がスキャンしたページの量 (無効な LRU リスト内)

	  pgscan_direct (npn)
		直接スキャンされたページの量 (無効な LRU リスト内)

	  pgscan_khugepaged (npn)
		khugepagedによってスキャンされたページの量 (無効なLRUリスト内)

	  pgsteal_kswapd (npn)
		kswapdによる再生ページ量。

	  pgsteal_direct (npn)
		直接再生されたページの量。

	  pgsteal_khugepaged (npn)
		khugepagedによって取り戻されたページの量。

	  pgfault (npn)
		発生したページフォルトの総数

	  pgmajfault (npn)
		発生したメジャーページフォルトの数

	  pgrefill (npn)
		(アクティブな LRU リスト内の) スキャンされたページの量。

	  pgactivate (npn)
		アクティブなLRUリストに移動したページの量

	  pgdeactivate (npn)
		非活性 LRU リストに移動したページ量。

	  pglazyfree (npn)
		メモリ不足のために解放が延期されたページの量。

	  pglazyfreed (npn)
		再生された遅延フリーページの量。

	  thp_fault_alloc (npn)
		ページフォールトを満たすために割り当てられた透過的なヒュッゲページの数。
		の数。このカウンタは CONFIG_TRANSPARENT_HUGEPAGE
                が設定されていない場合は存在しない。

	  thp_collapse_alloc (npn)
		既存のページ範囲を折りたたむために割り当てられた透過ヒュッゲページの数。
		既存のページ範囲を折りたたむために割り当てられた透明なヒュッゲページの数。このカウンタは
		CONFIG_TRANSPARENT_HUGEPAGE が設定されていないときは存在しない。

	  thp_swpout (npn)
		分割されずに一度にスワップアウトされる透過ヒュッゲページの数。
		分割せずに一度にスワップアウトされる透明なヒュッゲページの数。

	  thp_swpout_fallback (npn)
		スワップアウトの前に分割された透過 hugepage の数。
		通常、巨大ページのための連続的なスワップ領域の確保に失敗したためである。
		が失敗したため。

  memory.numa_stat
	非 root cgroup に存在する読み取り専用のネストされたキーファイル。

	これは、cgroup のメモリフットプリントをさまざまな
	メモリのタイプ、タイプ固有の詳細、およびメモリ管理の状態に関するノードごとのその他の情報
	メモリ管理システムの状態に関するノードごとの情報です。

	これは、memcg 内の NUMA ローカリティ情報を可視化するのに便利です。
	これは、memcg 内の NUMA ローカリティ情報を可視化するのに便利です。
	これは、memcg 内の NUMA ロカリティ情報を可視化するのに便利です。ユースケースの1つは
	この情報をアプリケーションのCPU割り当てと組み合わせることで
	アプリケーションの CPU 割り当てと組み合わせて、アプリケーションのパフォーマンスを評価することです。

	メモリ量はすべてバイト単位である。

	memory.numa_stat の出力形式は次のとおりです::

	  type N0=<bytes in node 0> N1=<bytes in node 1> ...

	エントリーは人間が読めるように順番に並べられており、新しいエントリーが途中で表示されることもある。
	エントリーは人間が読みやすいように並べられている。項目が一定の位置にあることを当てにしないでください。
	キーを使って特定の値を検索する！

	エントリーはmemory.stat.currentを参照できる。

  memory.swap.current
	非ルートのcグループに存在する読み取り専用の単一値ファイル。

	cgroup およびその子孫で現在使用されているスワップの合計量。
	およびその子孫で現在使用されているスワップの合計量です。

  memory.swap.high
	非ルートのcgroups に存在する読み書き可能な単一値ファイルです。 デフォルトは "max"。

	スワップ使用スロットルリミット。 cgroup のスワップ使用量が
	を超えると、それ以降のすべての割り当てがスロットルされます。
	ユーザースペースがカスタム メモリ外プロシージャを実装できるようにします。

	このリミットは cgroup の戻れないポイントになります。これは
	スワップの量を管理するように設計されていません。
  	このリミットは、cグループにとって戻れないポイントである。これは
	ワークロードのスワップ量を管理するようには設計されていません。
	を管理するためのものではありません。memory.swap.max と比較してください。
	と比較してください。
	は、他のメモリが再利用できる限り、無制限に継続される。

	健全なワークロードがこの制限に達することはない。

  memory.swap.peak
	非ルートのcグループに存在する読み取り専用の単一値ファイルです。

	cgroupとその子孫で記録された最大スワップ使用量。
	子孫に対して記録された最大スワップ使用量。

  memory.swap.max
	非ルートの cgroup に存在する読み書き可能な単一値ファイル。
	cgroup に存在する読み書き可能な単一値ファイルです。 デフォルトは「max」です。

	スワップ使用量のハードリミット。 cgroup のスワップ使用量がこの
	に達すると、cgroup の匿名メモリはスワップアウトされません。

  memory.swap.events
	非 root cgroup に存在する読み取り専用のフラットキーファイル。
	以下のエントリが定義されています。 以下のエントリが定義されています。
	このファイルの値が変更されると、ファイル
	変更イベントを生成します。

	  high
		cgroupのスワップ使用量が高閾値を超えた回数。
		を超えた回数。

	  max
		cgroup のスワップ使用量が最大値を超えようとしていた回数。
		スワップ割り当てが失敗した回数。
		に失敗した回数。

	  fail
		スワップ割り当てが失敗した回数。
		スワップ割り当てが失敗した回数。
		制限。

	現在の使用量でスワップが削減されると、既存のスワップ・エントリは徐々に回収され、スワップ使用量は維持される。
	エントリが徐々に回収され、スワップ使用量が制限値より高い状態が長期間続くことがある。
	スワップ使用量が上限より高い状態が これにより	は作業負荷とメモリ管理への影響を軽減する。

  memory.zswap.current
	非ルートの
	cグループに存在する読み取り専用の単一値ファイル。

	zswap圧縮バックエンドが消費するメモリの合計量。
	バックエンドによって消費されるメモリの総量。

  memory.zswap.max
	非ルートcグループに存在する読み書き可能な単一値ファイル。
	cgroupsに存在する読み書き可能な単一値ファイルです。 デフォルトは "max"。

	Zswap 使用のハードリミット。cgroup の zswap プールがこの制限に達すると
	に達すると、既存のエントリがフォールトバックされるか書き出される前に
	エントリがディスクに書き戻されるか書き出される前に、それ以上の保存を拒否します。

  memory.zswap.writeback
	読み書き可能な単一値ファイル。デフォルト値は「1」である。ルートcグループの初期値は
	ルート cgroup の初期値は 1 で、新しい cgroup が作成されると、親の現在の値を継承します。
	が作成されると、親の現在の値を継承する。

	この値を 0 に設定すると、スワッピングデバイスへのすべてのスワッピング試行
	へのスワッピングの試みはすべて無効になる。これには、zswapライトバックと、zswapストア失敗によるスワッピングの両方が含まれる。
	zswapストア失敗によるスワップも含まれる。zswapストアの失敗が繰り返される場合
	(ページが非圧縮性である場合など）。
	同じページが何度も拒否される可能性があるため）。

	これは、memory.swap.maxを
	0に設定するのとは微妙に異なることに注意してください。

  memory.pressure
	読み取り専用のネストされたキー・ファイル。

	メモリの圧力ストール情報を示す。参照
	詳細は :ref:`Documentation/accounting/psi.rst <psi>` を参照。

利用ガイドライン
~~~~~~~~~~~~~~~~

"memory.high "はメモリ使用量を制御する主なメカニズムである。
高リミットでのオーバーコミット（高リミットの合計＞利用可能メモリ）
を過剰にコミットし、グローバル・メモリー・プレッシャーに任せて使用量に応じてメモリーを分配するのは、有効な戦略です。
が有効な戦略である。

なぜなら、ハイリミットの違反は OOM キラーをトリガーせず、違反した cgroup をスロットルするからである。
管理エージェントには、次のような適切なアクションを取る十分な機会がある。
を監視し、適切なアクションを取る機会が十分にある。
メモリ増設やワークロードの終了など、適切なアクションを取ることができます。

cgroupに十分なメモリがあるかどうかを判断するのは簡単ではありません。
メモリ使用量は、ワークロードがより多くのメモリから利益を得られるかどうかを示さないからです。
とは限らないからである。 例えば、ネットワークから受信したデータをファイルに書き込むワークロードは、利用可能な メモリをすべて使用する可能性がある。
ネットワークから受信したデータをファイルに書き込むワークロードは、利用可能なメモリをすべて使用する可能性がありますが、少量のメモリで高いパフォーマンスを発揮することもできます。
として動作することもある。 メモリ
メモリ不足のために作業負荷がどの程度影響を受けているかを示すメモリ圧力の測定は、メモリが不足しているかどうかを判断するために必要です。
作業負荷がより多くのメモリを必要とするかどうかを判断するには、メモリ圧の測定が必要である。
残念ながら、メモリ不足監視メカニズムはまだ実装されていない。
残念ながら、メモリプレッシャー監視メカニズムはまだ実装されていない。

メモリの所有権
~~~~~~~~~~~~~~~~

メモリ領域は、それをインスタンス化した cgroup にチャージされ、領域が解放されるまで cgroup にチャージされたままになります。
にチャージされたままです。 プロセスを別の
プロセスを別の cgroup に移行しても、そのプロセスが前の cgroup にいる間にインスタンス化したメモリ使用量は移動しない。
を新しい cgroup に移動することはありません。

メモリ領域は、異なる cgroup に属するプロセスによって使用されることがあります。
しかし、その領域がどの cgroup にチャージされるかは不確定です、
メモリ領域がどの cgroup にチャージされるかは決定不可能である。
メモリ領域は、高いリクレイム圧力を回避するのに十分なメモリ許容量を持つcgroupに行き着く可能性が高い。

cgroup が、他の cgroup によって繰り返しアクセスされることが予想される、かなりの量のメモリをスイープする場合
他の cgroup によって繰り返しアクセスされることが予想される、かなりの量のメモリをスイープする場合は
POSIX_FADV_DONTNEED を使用して、 影響を受けるファイルに属するメモリ領域の所有権を放棄する。
を使用して、影響を受けるファイルに属するメモリ領域の所有権を放棄する。

IO
--

io」コントローラーは、IOリソースの分配を制御する。 このコントローラは、ウェイトベースの分配と、絶対的な帯域幅またはIOPS制限の分配の両方を実装している。blk-mqデバイスではどちらのスキームも利用できません。

IO インターフェースファイル
~~~~~~~~~~~~~~~~~~

 io.stat
	読み取り専用のネスト・キー・ファイル。

	行は$MAJ:$MINデバイス番号でキーが付けられ、順序は付けられない。
	以下のネストされたキーが定義されている。

	  ====== =====================
	  rbytes 読み込まれたバイト数
	  wbytes 書き込まれたバイト数
	  rios 読み込みIO数
	  wios 書き込み IO 数
	  dbytes 廃棄されたバイト数
	  dios 廃棄IO数
	  ====== =====================  

	  

	読み取り出力の例を以下に示す::

	  8:16 rbytes=1459200 wbytes=314773504 rios=192 wios=353 dbytes=0 dios=0
	  8:0 rbytes=90430464 wbytes=299008000 rios=8950 wios=1252 dbytes=50331648 dios=3021

  io.cost.qos
	rootにのみ存在する、読み書き可能なネストされたキー付きファイル。
	cgroupにのみ存在する。

	このファイルは、IOコストモデルベースのコントローラ(CONFIG_COST.qos)のサービス品質を設定します。
	モデルベースのコントローラ (CONFIG_BLK_CGROUP_IOCOST) のサービス品質を設定します。
	現在、「io.weight」比例制御を実装している。 行
	は、$MAJ:$MIN デバイス番号によってキー設定され、順序付けされていない。 並び順ではありません。
	行は、$MAJ:$MINのデバイス番号でキー設定され、順序はありません。
	行は、"io.cost.qos" または "io.cost.model "上のデバイスに対する最初の書き込み時に入力される。 以下の
	以下のネストされたキーが定義されている。

	  ====== =====================================
	  enable ウェイト制御 enable
	  ctrl "auto" または "user"
	  rpct 読み取り遅延パーセンタイル [0, 100］
	  rlat 読み出しレイテンシ閾値
	  wpct 書き込み遅延パーセンタイル [0, 100］
	  wlat 書き込み遅延のしきい値
	  min 最小スケーリングパーセンテージ [1, 10000］
	  max 最大スケーリング・パーセンテージ [1, 10000］
	  ====== =====================================

	コントローラーはデフォルトでは無効であり、enableを1に設定することで有効になる。
	enable "を "1 "に設定することで有効にできる。
	をゼロに設定し、コントローラは内部デバイスの飽和状態
	状態を使用して、全体のIOレートを "min "から "max "の間で調整する。

	より良い制御品質が必要な場合は、レイテンシQoS
	パラメータを設定することができる。 例えば、以下のようになる::

	  8:16 enable=1 ctrl=auto rpct=95.00 rlat=75000 wpct=95.00 wlat=150000 min=50.00 max=150.0

	は、sdbでコントローラーが有効になっていることを示す。
	デバイスが飽和したとみなす。
	レイテンシの95パーセンタイルが75msまたは150msを超えると、デバイスが飽和したとみなし、全体の
	を調整する。	飽和ポイントが低いほど、集約帯域幅を犠牲にして、レイテンシQoSが向上する。
	が向上する。 許容される
	最小 "と "最大 "の間の調整範囲が狭ければ狭いほど、IOの動作はコストモデル
	IOの動作がコストモデルに適合する。 IO問題
	基本レートが100%から大きく外れている可能性があり、"min "と "max "をやみくもに設定すると
	やみくもに "min "と "max "を設定すると、デバイスの容量や制御品質が著しく損なわれることがある。
	制御品質を著しく損なうことになる。 「min "と "max "は、以下のようなデバイスを制御するのに有用である。
	一時的に動作が大きく変化するデバイスを調整するのに便利です。
	ssdがしばらくの間ラインスピードで書き込みを受け付け、その後数秒間完全にストールする。
	その後何秒間も完全に停止する。

	以上から、内蔵の線形モデルは、逐次IOとランダムIOの基本コストとコスト係数を決定する。
	逐次IOとランダムIOの基本コストと、IOサイズに対するコスト係数
	を決定する。 単純ではあるが、このモデルは一般的なデバイスクラスをカバーできる。

	IOコストモデルは、絶対的な意味で正確であることは期待されていません。
	デバイスの動作に合わせて動的にスケーリングされる。

	必要であれば、tools/cgroup/iocost_coef_gen.py を使用して、デバイス固有の係数を生成できます。
	デバイス固有の係数を生成します。

  io.weight
	非 root cgroup に存在する読み書き可能なフラットキーファイル。
	デフォルトは "default 100 "です。

        最初の行はデバイスに適用されるデフォルトのウェイトです。
	残りの行は
	MAJ:$MINデバイス番号でキー設定されたオーバーライドで、順序はありません。 ウェイトは
	1, 10000] の範囲で、cgroup が使用できる相対的な IO 時間を指定します。
	を指定します。

	デフォルトの重みは、"default" または単に "$WEIGHT" と書くことで更新できる。 オーバーライドは
	「MAJ:$MIN$WEIGHT "と書くことで設定でき、"$MAJ:$MIN default "と書くことで解除できる。

	読み取り出力の例は以下の通り::

	  デフォルト 100
	  8:16 200
	  8:0 50

  io.max
	非ルートのファイル。

	BPSとIOPSベースのIO制限。 行は $MAJ:$MIN
	デバイス番号でキー付けされ、順序付けされていない。 以下のネストされたキーが定義されている。
	定義されている。

	  ===== ==================================
	  rbps 1秒あたりの最大読み取りバイト数
	  wbps 1 秒あたりの最大書き込みバイト数
	  riops 1 秒あたりの最大読み取り IO 操作数
	  wiops 最大書き込み IO
	  ===== ==================================

	書くときには、入れ子になったキーと値のペアをいくつでも、任意の順序で指定できる。
	を任意の順序で指定できる。 値として "max "を指定できます。
	を指定することができる。 同じキーが
	が複数回指定された場合、結果は未定義である。

	BPSとIOPSは各IO方向で測定され、IOは制限に達すると遅延される。
	は遅延される。 一時的なバーストは許される。

	8:16:の読み込み制限を2M BPS、書き込み制限を120 IOPSに設定する::

	  echo "8:16 rbps=2097152 wiops=120" > io.max

  読み込みは以下を返す::

	  8:16 rbps=2097152 wbps=max riops=max wiops=120

	書き込みIOPS制限は、次のように書くことで解除できる：

	  echo "8:16 wiops=max" > io.max

	読み込むと次のようになる：

	  8:16 rbps=2097152 wbps=max riops=max wiops=max

  io.pressure
	読み取り専用のネストされたキーファイル。

	IO の圧力失速情報を示す。参照
	詳細は :ref:`Documentation/accounting/psi.rst <psi>` を参照のこと。

Writeback
~~~~~~~~~

ページ・キャッシュはバッファード・ライトと共有mmapによって汚され、ライトバックによって非同期にバッキング・ファイルシステムに書き込まれる。
ライトバック・メカニズムによって非同期にバッキング・ファイルシステムに書き込まれる。
メカニズムによってバッキング・ファイルシステムに非同期に書き込まれる。 ライトバックはメモリとIOドメインの間に位置し
ダーティメモリの割合を調整する。
IOを書き込む。

IOコントローラは、メモリコントローラと連携して、ページキャッシュのライトバック制御を実装している、
ページキャッシュのライトバックIOの制御を実装している。 メモリコントローラ
メモリコントローラは、ダーティメモリ比率が計算され、維持されるメモリドメインを定義します。
メモリ・コントローラは、ダーティ・メモリ比率が計算され維持されるメモリ・ドメインを定義し、ioコントローラは
を定義する。 システム全体と
ダーティ・メモリの状態は、システム全体とグループごとに検査され、より制限の厳しい方
が強制される。

cgroupライトバックには、基礎となるファイルシステムからの明示的なサポートが必要です。 現在、cgroup writeback は ext2、ext4、btrfs、f2fs、および xfs で実装されています、
btrfs、f2fs、および xfs で実装されています。 その他のファイルシステムでは、すべてのライトバック IO は 
に帰属します。

メモリとライトバックの管理には固有の違いがあります。
に固有の違いがあり、cgroup の所有権の追跡方法に影響します。 メモリは
ページ単位で追跡されます。 ライトバックでは
inodeはcgroupに割り当てられ、inodeからダーティページを書き込むすべてのIOリクエストは
を書き込むすべての IO リクエストはその cgroup に帰属する。

メモリのcgroup所有権はページごとに追跡されるため、異なるcgroupに関連付けられたページが存在する可能性がある。
ページが存在する可能性があります。
とは異なるcgroupに関連付けられたページが存在することがある。 これらは外部ページと呼ばれる。 ライトバック
は常に

このモデルは、指定されたinodeが単一のcgroupによってほとんど汚されるようなほとんどのユースケースには十分である。
が単一のcgroupによってほとんど汚されるような使用例では、このモデルで十分である。
が変更されても、特定の inode が単一の cgroup によってほとんど汚されるような使用例では、このモデルで十分です。
に同時に書き込むような使用例はうまくサポートされません。 このような状況では
IOのかなりの部分が誤って帰属する可能性が高い。
メモリコントローラは最初の使用時にページの所有権を割り当て
ページが解放されるまで更新されないため、ライトバックがページ所有権に厳密に従うとしても
がページ所有権に厳密に従ったとしても、複数のcgroupが重複する領域
領域をダーティにする複数の  このような
パターンを避けることを推奨する。

ライトバックの動作に影響する sysctl ノブは、cgroup
ライトバックに適用されます。

  vm.dirty_background_ratio, vm.dirty_ratio
	これらの比率は、cgroupライトバックにも同じように適用されます。
	これらの比率はcgroup writebackにも適用されます。
	メモリコントローラとシステム全体のクリーンメモリによって制限されます。

  vm.dirty_background_bytes, vm.dirty_bytes
	cgroupライトバックの場合、これは次のように計算されます。
	と同じ方法で適用されます。
	vm.dirty[_background]_ratio と同じ方法で適用されます。

いったんここまで(2024/3/8)
続きは

IO Latency
~~~~~~~~~~
