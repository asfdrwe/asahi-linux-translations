`Control Group v2 <https://docs.kernel.org/admin-guide/cgroup-v2.html>`_  の非公式日本語訳です。
ライセンスは原文のライセンス(GPL-2.0のはず)に従います。

訳注: 

* まだDeepLの結果をはる途中(2024/3/9)
* ファイルがでかすぎるようなのでファイル分割(2024/3/9)

IO
--

io」コントローラーは、IOリソースの分配を制御する。 このコントローラは、ウェイトベースの分配と、絶対的な帯域幅またはIOPS制限の分配の両方を実装している。blk-mqデバイスではどちらのスキームも利用できません。

IO インターフェースファイル
~~~~~~~~~~~~~~~~~~

 io.stat
	読み取り専用のネスト・キー・ファイル。

	行は$MAJ:$MINデバイス番号でキーが付けられ、順序は付けられない。
	以下のネストされたキーが定義されている。

	  ====== =====================
	  rbytes 読み込まれたバイト数
	  wbytes 書き込まれたバイト数
	  rios 読み込みIO数
	  wios 書き込み IO 数
	  dbytes 廃棄されたバイト数
	  dios 廃棄IO数
	  ====== =====================  

	  

	読み取り出力の例を以下に示す::

	  8:16 rbytes=1459200 wbytes=314773504 rios=192 wios=353 dbytes=0 dios=0
	  8:0 rbytes=90430464 wbytes=299008000 rios=8950 wios=1252 dbytes=50331648 dios=3021

  io.cost.qos
	rootにのみ存在する、読み書き可能なネストされたキー付きファイル。
	cgroupにのみ存在する。

	このファイルは、IOコストモデルベースのコントローラ(CONFIG_COST.qos)のサービス品質を設定します。
	モデルベースのコントローラ (CONFIG_BLK_CGROUP_IOCOST) のサービス品質を設定します。
	現在、「io.weight」比例制御を実装している。 行
	は、$MAJ:$MIN デバイス番号によってキー設定され、順序付けされていない。 並び順ではありません。
	行は、$MAJ:$MINのデバイス番号でキー設定され、順序はありません。
	行は、"io.cost.qos" または "io.cost.model "上のデバイスに対する最初の書き込み時に入力される。 以下の
	以下のネストされたキーが定義されている。

	  ====== =====================================
	  enable ウェイト制御 enable
	  ctrl "auto" または "user"
	  rpct 読み取り遅延パーセンタイル [0, 100］
	  rlat 読み出しレイテンシ閾値
	  wpct 書き込み遅延パーセンタイル [0, 100］
	  wlat 書き込み遅延のしきい値
	  min 最小スケーリングパーセンテージ [1, 10000］
	  max 最大スケーリング・パーセンテージ [1, 10000］
	  ====== =====================================

	コントローラーはデフォルトでは無効であり、enableを1に設定することで有効になる。
	enable "を "1 "に設定することで有効にできる。
	をゼロに設定し、コントローラは内部デバイスの飽和状態
	状態を使用して、全体のIOレートを "min "から "max "の間で調整する。

	より良い制御品質が必要な場合は、レイテンシQoS
	パラメータを設定することができる。 例えば、以下のようになる::

	  8:16 enable=1 ctrl=auto rpct=95.00 rlat=75000 wpct=95.00 wlat=150000 min=50.00 max=150.0

	は、sdbでコントローラーが有効になっていることを示す。
	デバイスが飽和したとみなす。
	レイテンシの95パーセンタイルが75msまたは150msを超えると、デバイスが飽和したとみなし、全体の
	を調整する。	飽和ポイントが低いほど、集約帯域幅を犠牲にして、レイテンシQoSが向上する。
	が向上する。 許容される
	最小 "と "最大 "の間の調整範囲が狭ければ狭いほど、IOの動作はコストモデル
	IOの動作がコストモデルに適合する。 IO問題
	基本レートが100%から大きく外れている可能性があり、"min "と "max "をやみくもに設定すると
	やみくもに "min "と "max "を設定すると、デバイスの容量や制御品質が著しく損なわれることがある。
	制御品質を著しく損なうことになる。 「min "と "max "は、以下のようなデバイスを制御するのに有用である。
	一時的に動作が大きく変化するデバイスを調整するのに便利です。
	ssdがしばらくの間ラインスピードで書き込みを受け付け、その後数秒間完全にストールする。
	その後何秒間も完全に停止する。

	以上から、内蔵の線形モデルは、逐次IOとランダムIOの基本コストとコスト係数を決定する。
	逐次IOとランダムIOの基本コストと、IOサイズに対するコスト係数
	を決定する。 単純ではあるが、このモデルは一般的なデバイスクラスをカバーできる。

	IOコストモデルは、絶対的な意味で正確であることは期待されていません。
	デバイスの動作に合わせて動的にスケーリングされる。

	必要であれば、tools/cgroup/iocost_coef_gen.py を使用して、デバイス固有の係数を生成できます。
	デバイス固有の係数を生成します。

  io.weight
	非 root cgroup に存在する読み書き可能なフラットキーファイル。
	デフォルトは "default 100 "です。

        最初の行はデバイスに適用されるデフォルトのウェイトです。
	残りの行は
	MAJ:$MINデバイス番号でキー設定されたオーバーライドで、順序はありません。 ウェイトは
	1, 10000] の範囲で、cgroup が使用できる相対的な IO 時間を指定します。
	を指定します。

	デフォルトの重みは、"default" または単に "$WEIGHT" と書くことで更新できる。 オーバーライドは
	「MAJ:$MIN$WEIGHT "と書くことで設定でき、"$MAJ:$MIN default "と書くことで解除できる。

	読み取り出力の例は以下の通り::

	  デフォルト 100
	  8:16 200
	  8:0 50

  io.max
	非ルートのファイル。

	BPSとIOPSベースのIO制限。 行は $MAJ:$MIN
	デバイス番号でキー付けされ、順序付けされていない。 以下のネストされたキーが定義されている。
	定義されている。

	  ===== ==================================
	  rbps 1秒あたりの最大読み取りバイト数
	  wbps 1 秒あたりの最大書き込みバイト数
	  riops 1 秒あたりの最大読み取り IO 操作数
	  wiops 最大書き込み IO
	  ===== ==================================

	書くときには、入れ子になったキーと値のペアをいくつでも、任意の順序で指定できる。
	を任意の順序で指定できる。 値として "max "を指定できます。
	を指定することができる。 同じキーが
	が複数回指定された場合、結果は未定義である。

	BPSとIOPSは各IO方向で測定され、IOは制限に達すると遅延される。
	は遅延される。 一時的なバーストは許される。

	8:16:の読み込み制限を2M BPS、書き込み制限を120 IOPSに設定する::

	  echo "8:16 rbps=2097152 wiops=120" > io.max

  読み込みは以下を返す::

	  8:16 rbps=2097152 wbps=max riops=max wiops=120

	書き込みIOPS制限は、次のように書くことで解除できる：

	  echo "8:16 wiops=max" > io.max

	読み込むと次のようになる：

	  8:16 rbps=2097152 wbps=max riops=max wiops=max

  io.pressure
	読み取り専用のネストされたキーファイル。

	IO の圧力失速情報を示す。参照
	詳細は :ref:`Documentation/accounting/psi.rst <psi>` を参照のこと。

Writeback
~~~~~~~~~

ページ・キャッシュはバッファード・ライトと共有mmapによって汚され、ライトバックによって非同期にバッキング・ファイルシステムに書き込まれる。
ライトバック・メカニズムによって非同期にバッキング・ファイルシステムに書き込まれる。
メカニズムによってバッキング・ファイルシステムに非同期に書き込まれる。 ライトバックはメモリとIOドメインの間に位置し
ダーティメモリの割合を調整する。
IOを書き込む。

IOコントローラは、メモリコントローラと連携して、ページキャッシュのライトバック制御を実装している、
ページキャッシュのライトバックIOの制御を実装している。 メモリコントローラ
メモリコントローラは、ダーティメモリ比率が計算され、維持されるメモリドメインを定義します。
メモリ・コントローラは、ダーティ・メモリ比率が計算され維持されるメモリ・ドメインを定義し、ioコントローラは
を定義する。 システム全体と
ダーティ・メモリの状態は、システム全体とグループごとに検査され、より制限の厳しい方
が強制される。

cgroupライトバックには、基礎となるファイルシステムからの明示的なサポートが必要です。 現在、cgroup writeback は ext2、ext4、btrfs、f2fs、および xfs で実装されています、
btrfs、f2fs、および xfs で実装されています。 その他のファイルシステムでは、すべてのライトバック IO は 
に帰属します。

メモリとライトバックの管理には固有の違いがあります。
に固有の違いがあり、cgroup の所有権の追跡方法に影響します。 メモリは
ページ単位で追跡されます。 ライトバックでは
inodeはcgroupに割り当てられ、inodeからダーティページを書き込むすべてのIOリクエストは
を書き込むすべての IO リクエストはその cgroup に帰属する。

メモリのcgroup所有権はページごとに追跡されるため、異なるcgroupに関連付けられたページが存在する可能性がある。
ページが存在する可能性があります。
とは異なるcgroupに関連付けられたページが存在することがある。 これらは外部ページと呼ばれる。 ライトバック
は常に

このモデルは、指定されたinodeが単一のcgroupによってほとんど汚されるようなほとんどのユースケースには十分である。
が単一のcgroupによってほとんど汚されるような使用例では、このモデルで十分である。
が変更されても、特定の inode が単一の cgroup によってほとんど汚されるような使用例では、このモデルで十分です。
に同時に書き込むような使用例はうまくサポートされません。 このような状況では
IOのかなりの部分が誤って帰属する可能性が高い。
メモリコントローラは最初の使用時にページの所有権を割り当て
ページが解放されるまで更新されないため、ライトバックがページ所有権に厳密に従うとしても
がページ所有権に厳密に従ったとしても、複数のcgroupが重複する領域
領域をダーティにする複数の  このような
パターンを避けることを推奨する。

ライトバックの動作に影響する sysctl ノブは、cgroup
ライトバックに適用されます。

  vm.dirty_background_ratio, vm.dirty_ratio
	これらの比率は、cgroupライトバックにも同じように適用されます。
	これらの比率はcgroup writebackにも適用されます。
	メモリコントローラとシステム全体のクリーンメモリによって制限されます。

  vm.dirty_background_bytes, vm.dirty_bytes
	cgroupライトバックの場合、これは次のように計算されます。
	と同じ方法で適用されます。
	vm.dirty[_background]_ratio と同じ方法で適用されます。

いったんここまで(2024/3/8)
続きは

IO Latency
~~~~~~~~~~
